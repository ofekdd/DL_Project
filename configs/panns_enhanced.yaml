# PANNs-enhanced model configuration
model_name: panns_enhanced
sample_rate: 22050
n_mels: 64
hop_length: 512
batch_size: 48  # Smaller batch size due to larger model
num_workers: 2

# PANNs-specific settings
frozen_learning_rate: 0.003  # Higher LR when backbone frozen
finetune_learning_rate: 0.0002  # Adjusted LR for fine-tuning

# Learning rate scheduler settings
use_lr_scheduler: true  # Enable learning rate scheduler
lr_scheduler_type: "cosine"  # Cosine annealing scheduler
lr_warmup_epochs: 5  # Number of warmup epochs for scheduler
lr_min_factor: 0.01  # Minimum LR factor (final LR = initial LR * min_factor)

# Training efficiency settings
num_sanity_val_steps: 2  # Reduce sanity validation steps for faster startup

# Training dataset settings
num_epochs: 200  # Extended for two-phase training, for fast run: 2
freeze_epochs: 4  # Increased initial epochs with frozen backbone, for fast run: 1
limit_val_batches: 1.0  # Use all validation data for reliable metrics, for fast run: 0.2
original_data_percentage: 1  # Use all original IRMAS data, for fast run: 0.1
max_original_samples: null  # Use all original samples, for fast run: 20
max_samples: null  # Maximum samples to use for training (None for all), for fast run: 20
max_test_samples: null # Maximum samples to use for testing (None for all), for fast run: 20
