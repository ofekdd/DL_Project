{
 "cells": [
  {
   "metadata": {
    "id": "72f151f9e587ca61"
   },
   "cell_type": "markdown",
   "source": [
    "# Instrument Classifier\n",
    "\n",
    "This notebook demonstrates a PyTorch project for multi-label musical instrument recognition from audio clips. It allows you to run the entire pipeline in Google Colab without any special modifications to the codebase.\n",
    "\n",
    "## Setup\n",
    "\n",
    "First, let's clone the repository and install the required dependencies.\n"
   ],
   "id": "72f151f9e587ca61"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-31T09:04:34.080277Z",
     "start_time": "2025-05-31T09:04:34.075850Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e41cf2ee959bd67c",
    "outputId": "6552404d-c800-49da-b8fe-f3f1211296c2"
   },
   "cell_type": "code",
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "# Check if running in Colab\n",
    "import sys\n",
    "\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "\n",
    "if IN_COLAB:\n",
    "    # Clone the repository\n",
    "    !git clone https://github.com/ofekdd/DL_Project.git\n",
    "    %cd DL_Project\n",
    "\n",
    "    # Install dependencies\n",
    "    !pip install -r requirements.txt\n"
   ],
   "id": "e41cf2ee959bd67c",
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "fatal: destination path 'DL_Project' already exists and is not an empty directory.\n",
      "/content/DL_Project\n",
      "Requirement already satisfied: torch>=2.7.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 1)) (2.7.0)\n",
      "Requirement already satisfied: lightning-fabric==2.0.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 2)) (2.0.0)\n",
      "Requirement already satisfied: librosa>=0.10 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 3)) (0.11.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 4)) (2.0.2)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 5)) (1.15.3)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 6)) (4.67.1)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 7)) (6.0.2)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 8)) (3.10.0)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 9)) (1.6.1)\n",
      "Requirement already satisfied: torchmetrics>=1.3 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 10)) (1.7.2)\n",
      "Requirement already satisfied: streamlit in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 11)) (1.45.1)\n",
      "Requirement already satisfied: torchvision>=0.15.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 12)) (0.22.0)\n",
      "Requirement already satisfied: fsspec>2021.06.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>2021.06.0->lightning-fabric==2.0.0->-r requirements.txt (line 2)) (2025.3.2)\n",
      "Requirement already satisfied: packaging>=17.1 in /usr/local/lib/python3.11/dist-packages (from lightning-fabric==2.0.0->-r requirements.txt (line 2)) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from lightning-fabric==2.0.0->-r requirements.txt (line 2)) (4.13.2)\n",
      "Requirement already satisfied: lightning-utilities>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from lightning-fabric==2.0.0->-r requirements.txt (line 2)) (0.14.3)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.7.0->-r requirements.txt (line 1)) (3.18.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.7.0->-r requirements.txt (line 1)) (1.14.0)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.7.0->-r requirements.txt (line 1)) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.7.0->-r requirements.txt (line 1)) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.11/dist-packages (from torch>=2.7.0->-r requirements.txt (line 1)) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.11/dist-packages (from torch>=2.7.0->-r requirements.txt (line 1)) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.11/dist-packages (from torch>=2.7.0->-r requirements.txt (line 1)) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in /usr/local/lib/python3.11/dist-packages (from torch>=2.7.0->-r requirements.txt (line 1)) (9.5.1.17)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.7.0->-r requirements.txt (line 1)) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.11/dist-packages (from torch>=2.7.0->-r requirements.txt (line 1)) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.11/dist-packages (from torch>=2.7.0->-r requirements.txt (line 1)) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.7.0->-r requirements.txt (line 1)) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.7.0->-r requirements.txt (line 1)) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.7.0->-r requirements.txt (line 1)) (0.6.3)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.26.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.7.0->-r requirements.txt (line 1)) (2.26.2)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.11/dist-packages (from torch>=2.7.0->-r requirements.txt (line 1)) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.11/dist-packages (from torch>=2.7.0->-r requirements.txt (line 1)) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.11/dist-packages (from torch>=2.7.0->-r requirements.txt (line 1)) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.3.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.7.0->-r requirements.txt (line 1)) (3.3.0)\n",
      "Requirement already satisfied: setuptools>=40.8.0 in /usr/local/lib/python3.11/dist-packages (from triton==3.3.0->torch>=2.7.0->-r requirements.txt (line 1)) (75.2.0)\n",
      "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.10->-r requirements.txt (line 3)) (3.0.1)\n",
      "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.10->-r requirements.txt (line 3)) (0.60.0)\n",
      "Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.10->-r requirements.txt (line 3)) (1.5.0)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.10->-r requirements.txt (line 3)) (4.4.2)\n",
      "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.10->-r requirements.txt (line 3)) (0.13.1)\n",
      "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.10->-r requirements.txt (line 3)) (1.8.2)\n",
      "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.10->-r requirements.txt (line 3)) (0.5.0.post1)\n",
      "Requirement already satisfied: lazy_loader>=0.1 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.10->-r requirements.txt (line 3)) (0.4)\n",
      "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa>=0.10->-r requirements.txt (line 3)) (1.1.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 8)) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 8)) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 8)) (4.58.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 8)) (1.4.8)\n",
      "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 8)) (11.2.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 8)) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 8)) (2.9.0.post0)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->-r requirements.txt (line 9)) (3.6.0)\n",
      "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit->-r requirements.txt (line 11)) (5.5.0)\n",
      "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from streamlit->-r requirements.txt (line 11)) (1.9.0)\n",
      "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit->-r requirements.txt (line 11)) (5.5.2)\n",
      "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit->-r requirements.txt (line 11)) (8.2.1)\n",
      "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit->-r requirements.txt (line 11)) (2.2.2)\n",
      "Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.11/dist-packages (from streamlit->-r requirements.txt (line 11)) (5.29.4)\n",
      "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit->-r requirements.txt (line 11)) (18.1.0)\n",
      "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.11/dist-packages (from streamlit->-r requirements.txt (line 11)) (2.32.3)\n",
      "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit->-r requirements.txt (line 11)) (9.1.2)\n",
      "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from streamlit->-r requirements.txt (line 11)) (0.10.2)\n",
      "Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.11/dist-packages (from streamlit->-r requirements.txt (line 11)) (6.0.0)\n",
      "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.11/dist-packages (from streamlit->-r requirements.txt (line 11)) (3.1.44)\n",
      "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.11/dist-packages (from streamlit->-r requirements.txt (line 11)) (0.9.1)\n",
      "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.11/dist-packages (from streamlit->-r requirements.txt (line 11)) (6.4.2)\n",
      "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit->-r requirements.txt (line 11)) (4.23.0)\n",
      "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit->-r requirements.txt (line 11)) (1.40.0)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>2021.06.0->lightning-fabric==2.0.0->-r requirements.txt (line 2)) (3.11.15)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit->-r requirements.txt (line 11)) (4.0.12)\n",
      "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.51.0->librosa>=0.10->-r requirements.txt (line 3)) (0.43.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit->-r requirements.txt (line 11)) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit->-r requirements.txt (line 11)) (2025.2)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa>=0.10->-r requirements.txt (line 3)) (4.3.8)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.7.0->-r requirements.txt (line 1)) (3.0.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->-r requirements.txt (line 8)) (1.17.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit->-r requirements.txt (line 11)) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit->-r requirements.txt (line 11)) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit->-r requirements.txt (line 11)) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit->-r requirements.txt (line 11)) (2025.4.26)\n",
      "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile>=0.12.1->librosa>=0.10->-r requirements.txt (line 3)) (1.17.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy>=1.13.3->torch>=2.7.0->-r requirements.txt (line 1)) (1.3.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->lightning-fabric==2.0.0->-r requirements.txt (line 2)) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->lightning-fabric==2.0.0->-r requirements.txt (line 2)) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->lightning-fabric==2.0.0->-r requirements.txt (line 2)) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->lightning-fabric==2.0.0->-r requirements.txt (line 2)) (1.6.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->lightning-fabric==2.0.0->-r requirements.txt (line 2)) (6.4.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->lightning-fabric==2.0.0->-r requirements.txt (line 2)) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->lightning-fabric==2.0.0->-r requirements.txt (line 2)) (1.20.0)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa>=0.10->-r requirements.txt (line 3)) (2.22)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit->-r requirements.txt (line 11)) (5.0.2)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit->-r requirements.txt (line 11)) (2025.4.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit->-r requirements.txt (line 11)) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit->-r requirements.txt (line 11)) (0.25.1)\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {
    "id": "26c0112ad361303c"
   },
   "cell_type": "markdown",
   "source": [
    "## Import Libraries\n",
    "\n",
    "Let's import the necessary libraries for our project.\n"
   ],
   "id": "26c0112ad361303c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-31T09:25:32.942983Z",
     "start_time": "2025-05-31T09:25:32.916869Z"
    },
    "id": "347e90cad1a1ade4"
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import torch\n",
    "import librosa\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import yaml\n",
    "import pathlib\n",
    "import zipfile\n",
    "import urllib.request\n",
    "import hashlib\n",
    "import sys\n",
    "import time\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import warnings, tqdm\n",
    "warnings.filterwarnings(\"ignore\", category=tqdm.TqdmWarning)\n",
    "\n",
    "# ---- force classic text progress bar ----\n",
    "import importlib, sys\n",
    "import tqdm\n",
    "sys.modules['tqdm.notebook'] = tqdm\n",
    "sys.modules['tqdm.autonotebook'] = tqdm\n",
    "from tqdm import tqdm  # now `tqdm(...)` is always the console bar\n",
    "\n"
   ],
   "id": "347e90cad1a1ade4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "id": "47340b13e48e8ee6"
   },
   "cell_type": "markdown",
   "source": [
    "## Configuration\n",
    "\n",
    "Let's define the configuration for our project.\n"
   ],
   "id": "47340b13e48e8ee6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-31T09:13:20.667247Z",
     "start_time": "2025-05-31T09:13:20.651609Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "18931ecd85bfbbf4",
    "outputId": "bac1dfdf-468c-4723-d70e-509d9f21be22"
   },
   "cell_type": "code",
   "source": [
    "# Create configs directory if it doesn't exist\n",
    "os.makedirs('configs', exist_ok=True)\n",
    "\n",
    "# Default configuration\n",
    "default_config = \"\"\"\n",
    "# Common hyper‑parameters\n",
    "sample_rate: 22050\n",
    "n_mels: 64\n",
    "hop_length: 512\n",
    "batch_size: 32\n",
    "num_epochs: 50\n",
    "learning_rate: 3e-4\n",
    "num_workers: 4\n",
    "\"\"\"\n",
    "\n",
    "# ResNet configuration\n",
    "resnet_config = \"\"\"\n",
    "# ResNet‑34 override\n",
    "model_name: resnet34\n",
    "learning_rate: 1e-4\n",
    "batch_size: 16\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# Write configurations to files\n",
    "with open('configs/default.yaml', 'w', encoding='utf-8') as f:\n",
    "    f.write(default_config)\n",
    "\n",
    "with open('configs/model_resnet.yaml', 'w', encoding='utf-8') as f:\n",
    "    f.write(resnet_config)\n",
    "# Load configuration\n",
    "cfg = yaml.safe_load(default_config)\n",
    "resnet_cfg = {**cfg, **yaml.safe_load(resnet_config)}\n",
    "\n",
    "# Display configuration\n",
    "print(\"Default configuration:\")\n",
    "for key, value in cfg.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "print(\"\\nResNet configuration:\")\n",
    "for key, value in resnet_cfg.items():\n",
    "    print(f\"  {key}: {value}\")\n"
   ],
   "id": "18931ecd85bfbbf4",
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Default configuration:\n",
      "  sample_rate: 22050\n",
      "  n_mels: 64\n",
      "  hop_length: 512\n",
      "  batch_size: 32\n",
      "  num_epochs: 50\n",
      "  learning_rate: 3e-4\n",
      "  num_workers: 4\n",
      "\n",
      "ResNet configuration:\n",
      "  sample_rate: 22050\n",
      "  n_mels: 64\n",
      "  hop_length: 512\n",
      "  batch_size: 16\n",
      "  num_epochs: 50\n",
      "  learning_rate: 1e-4\n",
      "  num_workers: 4\n",
      "  model_name: resnet34\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {
    "id": "537b6591baeeddc2"
   },
   "cell_type": "markdown",
   "source": [
    "## Download and Extract Data\n",
    "\n",
    "Let's download and extract the IRMAS dataset.\n"
   ],
   "id": "537b6591baeeddc2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-31T09:06:26.090010Z",
     "start_time": "2025-05-31T09:04:34.279183Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a727eb431b0fd307",
    "outputId": "8b189a9e-f1af-40f1-e7c7-53e8c098508e"
   },
   "cell_type": "code",
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"Download the **raw** IRMAS zip (≈ 3 GB) to a persistent location\n",
    "(Drive if running in Colab) and *optionally* extract it to a **scratch** folder\n",
    "inside the current runtime.  The extracted data is therefore rebuilt every\n",
    "session, keeping Google Drive usage tiny (≈ 3 GB).\n",
    "\n",
    "Typical Colab usage\n",
    "-------------------\n",
    "```python\n",
    "!python data/download_irmas.py                   # zip → Drive, extract → /content/IRMAS\n",
    "```\n",
    "\n",
    "Local (non‑Colab) usage – behaves like the original script:\n",
    "```bash\n",
    "python data/download_irmas.py --out_dir data/raw  # zip + extract inside repo\n",
    "```\n",
    "\"\"\"\n",
    "\n",
    "import argparse, hashlib, os, pathlib, sys, urllib.request, zipfile\n",
    "\n",
    "IRMAS_URL = (\n",
    "    \"https://zenodo.org/records/1290750/files/IRMAS-TrainingData.zip?download=1\"\n",
    ")\n",
    "MD5 = \"4fd9f5ed5a18d8e2687e6360b5f60afe\"  # expected archive checksum\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Helpers\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "def inside_colab() -> bool:\n",
    "    return \"google.colab\" in sys.modules\n",
    "\n",
    "\n",
    "def ensure_drive_mounted():\n",
    "    \"\"\"Mount Google Drive once per Colab session.\"\"\"\n",
    "    if not inside_colab():\n",
    "        return\n",
    "    from google.colab import drive  # type: ignore  # noqa\n",
    "\n",
    "    drive_root = pathlib.Path(\"/content/drive\")\n",
    "    if not drive_root.is_dir():\n",
    "        print(\"Mounting Google Drive …\")\n",
    "        drive.mount(\"/content/drive\")\n",
    "\n",
    "\n",
    "def md5(path: pathlib.Path, chunk: int = 2 ** 20) -> str:\n",
    "    h = hashlib.md5()\n",
    "    with path.open(\"rb\") as fh:\n",
    "        for blk in iter(lambda: fh.read(chunk), b\"\"):\n",
    "            h.update(blk)\n",
    "    return h.hexdigest()\n",
    "\n",
    "\n",
    "def download_zip(zip_path: pathlib.Path):\n",
    "    print(\"Downloading IRMAS zip …\")\n",
    "    try:\n",
    "        urllib.request.urlretrieve(IRMAS_URL, zip_path)\n",
    "    except Exception as e:\n",
    "        print(f\"Download failed: {e}\", file=sys.stderr)\n",
    "        sys.exit(1)\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Main routine\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "def main(zip_dir: pathlib.Path):\n",
    "    \"\"\"Ensure the IRMAS zip is present in *zip_dir* (persistent).\n",
    "    In Colab, also extract to /content/IRMAS every session.\n",
    "    \"\"\"\n",
    "    zip_dir.mkdir(parents=True, exist_ok=True)\n",
    "    zip_path = zip_dir / \"IRMAS.zip\"\n",
    "\n",
    "    # 1) download once ------------------------------------------------------\n",
    "    if zip_path.exists():\n",
    "        print(\"Zip already in cache – skipping download\")\n",
    "    else:\n",
    "        download_zip(zip_path)\n",
    "\n",
    "    # 2) checksum -----------------------------------------------------------\n",
    "    print(\"Verifying checksum …\")\n",
    "    if md5(zip_path) != MD5:\n",
    "        print(\"❌  MD5 mismatch – delete the zip and rerun.\", file=sys.stderr)\n",
    "        sys.exit(1)\n",
    "\n",
    "    # 3) decide where to extract -------------------------------------------\n",
    "    if inside_colab():\n",
    "        extract_root = pathlib.Path(\"/content/IRMAS\")\n",
    "    else:\n",
    "        extract_root = zip_path.parent / \"IRMAS\"\n",
    "\n",
    "    if extract_root.is_dir():\n",
    "        print(\"Extracted folder already exists – skipping unzip\")\n",
    "        print(\"Data ready at\", extract_root)\n",
    "        return\n",
    "\n",
    "    print(f\"Extracting to {extract_root} … (this happens each new runtime)\")\n",
    "    with zipfile.ZipFile(zip_path) as zf:\n",
    "        zf.extractall(extract_root)\n",
    "    print(\"✅  Done. Data at\", extract_root)\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# CLI\n",
    "# ---------------------------------------------------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    default_out = (\n",
    "        \"/content/drive/MyDrive/datasets/IRMAS\"\n",
    "        if inside_colab()\n",
    "        else \"data/raw/IRMAS\"\n",
    "    )\n",
    "\n",
    "    parser = argparse.ArgumentParser(\n",
    "        description=\"Download IRMAS zip to a persistent folder. In Colab the zip \"\n",
    "        \"lives on Drive but extraction goes to /content/IRMAS so Drive quota \"\n",
    "        \"remains low.\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--out_dir\",\n",
    "        default=default_out,\n",
    "        help=\"Folder where the IRMAS.zip will be cached (Drive for Colab).\",\n",
    "    )\n",
    "\n",
    "    args, _ = parser.parse_known_args()\n",
    "\n",
    "    ensure_drive_mounted()\n",
    "    main(pathlib.Path(args.out_dir))\n"
   ],
   "id": "a727eb431b0fd307",
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Mounting Google Drive …\n",
      "Mounted at /content/drive\n",
      "Downloading IRMAS zip …\n",
      "Verifying checksum …\n",
      "Extracting to /content/IRMAS … (this happens each new runtime)\n",
      "✅  Done. Data at /content/IRMAS\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {
    "id": "a0d58f1bc5caab81"
   },
   "cell_type": "markdown",
   "source": [
    "## Preprocess Data\n",
    "\n",
    "Let's preprocess the data by converting WAV files to log-mel spectrograms.\n"
   ],
   "id": "a0d58f1bc5caab81"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-31T09:12:32.362864Z",
     "start_time": "2025-05-31T09:06:26.173151Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6cb3934599e423b1",
    "outputId": "4ec37c9d-4a34-4434-be2c-6ee53b7070ec"
   },
   "cell_type": "code",
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def generate_multi_stft(\n",
    "    y: np.ndarray,\n",
    "    sr: int,\n",
    "    n_ffts = (256, 512, 1024),\n",
    "    band_ranges = ((0, 1000), (1000, 4000), (4000, 11025))\n",
    "):\n",
    "    \"\"\"\n",
    "    Returns { (band_label, n_fft): log-magnitude spectrogram }.\n",
    "    3 window sizes × 3 frequency bands = 9 specs per clip.\n",
    "    \"\"\"\n",
    "    result = {}\n",
    "    for n_fft in n_ffts:\n",
    "        hop_length = n_fft // 4\n",
    "        mag = np.abs(librosa.stft(y, n_fft=n_fft, hop_length=hop_length))\n",
    "\n",
    "        freqs = librosa.fft_frequencies(sr=sr, n_fft=n_fft)\n",
    "        for f_low, f_high in band_ranges:\n",
    "            band_label = f\"{f_low}-{f_high}Hz\"\n",
    "            band_mask  = (freqs >= f_low) & (freqs < f_high)\n",
    "            band_spec  = mag[band_mask]\n",
    "            log_spec   = librosa.amplitude_to_db(band_spec,\n",
    "                                                 ref=np.max).astype(np.float32)\n",
    "            result[(band_label, n_fft)] = log_spec\n",
    "    return result\n",
    "\n",
    "\n",
    "# --------------------------------------------------------------------\n",
    "# 2. Single-file processor\n",
    "# --------------------------------------------------------------------\n",
    "def process_file(wav_path: pathlib.Path, cfg: dict):\n",
    "    y, sr = librosa.load(wav_path, sr=cfg[\"sample_rate\"], mono=True)\n",
    "    return generate_multi_stft(y, sr)\n",
    "\n",
    "\n",
    "# --------------------------------------------------------------------\n",
    "# 3. Bulk preprocessing with 90 / 10 split\n",
    "# --------------------------------------------------------------------\n",
    "def preprocess_data(in_dir: str, out_dir: str, cfg: dict):\n",
    "    in_dir  = pathlib.Path(in_dir)\n",
    "    out_dir = pathlib.Path(out_dir)\n",
    "    train_dir, val_dir = out_dir / \"train\", out_dir / \"val\"\n",
    "    for d in (train_dir, val_dir):\n",
    "        d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    wav_files = list(in_dir.rglob(\"*.wav\"))\n",
    "    if not wav_files:\n",
    "        print(f\"‼️  No WAV files under {in_dir}\")\n",
    "        return\n",
    "    print(f\"Found {len(wav_files)} WAV files\")\n",
    "\n",
    "    np.random.shuffle(wav_files)\n",
    "    split = int(len(wav_files) * 0.9)\n",
    "    splits = {\"train\": wav_files[:split], \"val\": wav_files[split:]}\n",
    "\n",
    "    for split_name, files in splits.items():\n",
    "        print(f\"Processing {split_name} files …\")\n",
    "        base_out = train_dir if split_name == \"train\" else val_dir\n",
    "        for wav in tqdm(files):\n",
    "            specs = process_file(wav, cfg)\n",
    "\n",
    "            rel_dir = wav.relative_to(in_dir).with_suffix(\"\")\n",
    "            (base_out / rel_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "            for (band_label, n_fft), spec in specs.items():\n",
    "                fname = f\"{band_label}_fft{n_fft}.npy\"\n",
    "                np.save(base_out / rel_dir / fname, spec)\n",
    "\n",
    "    print(f\"✅  Done. {len(splits['train'])} train / {len(splits['val'])} val clips\")\n",
    "\n",
    "\n",
    "# --------------------------------------------------------------------\n",
    "# 4. Locate audio automatically\n",
    "# --------------------------------------------------------------------\n",
    "def find_irmas_root() -> pathlib.Path | None:\n",
    "    \"\"\"Return the first existing path that contains IRMAS WAVs.\"\"\"\n",
    "    candidates = [\n",
    "        pathlib.Path(\"/content/IRMAS/IRMAS-TrainingData\"),   # Colab scratch\n",
    "        pathlib.Path(\"data/raw/IRMAS/IRMAS-TrainingData\"),   # legacy\n",
    "        pathlib.Path(\"data/raw/IRMAS-TrainingData\"),         # legacy alt\n",
    "        pathlib.Path(\"data/raw\"),                            # fallback\n",
    "    ]\n",
    "    for p in candidates:\n",
    "        if p.exists() and any(p.rglob(\"*.wav\")):\n",
    "            return p\n",
    "    return None\n",
    "\n",
    "\n",
    "# --------------------------------------------------------------------\n",
    "# 5. Run\n",
    "# --------------------------------------------------------------------\n",
    "cfg = yaml.safe_load(open(\"configs/default.yaml\"))\n",
    "irmas_root = find_irmas_root()\n",
    "\n",
    "if irmas_root is None:\n",
    "    print(\"❌  No IRMAS audio found. Did you run download_irmas.py yet?\")\n",
    "else:\n",
    "    print(f\"Using IRMAS root: {irmas_root}\")\n",
    "    preprocess_data(irmas_root, \"data/processed\", cfg)"
   ],
   "id": "6cb3934599e423b1",
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Using IRMAS root: /content/IRMAS/IRMAS-TrainingData\n",
      "Found 6705 WAV files\n",
      "Processing train files …\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 6034/6034 [02:42<00:00, 37.05it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Processing val files …\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 671/671 [00:16<00:00, 41.93it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "✅  Done. 6034 train / 671 val clips\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {
    "id": "ce41935b553f98c6"
   },
   "cell_type": "markdown",
   "source": [
    "## Define Models\n",
    "\n",
    "Let's define the models for our project.\n"
   ],
   "id": "ce41935b553f98c6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-31T09:12:48.383407Z",
     "start_time": "2025-05-31T09:12:48.115487Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "984567832a6a1ef9",
    "outputId": "3c336b2a-1321-4463-d01c-00f846ae5a4d"
   },
   "cell_type": "code",
   "source": [
    "import torch.nn as nn\n",
    "from torchvision.models import resnet34\n",
    "\n",
    "# Create models directory if it doesn't exist\n",
    "os.makedirs('models', exist_ok=True)\n",
    "\n",
    "class CNNBaseline(nn.Module):\n",
    "    \"\"\"Simple CNN baseline for audio classification.\"\"\"\n",
    "    def __init__(self, n_classes=11):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(64 * 8 * 8, 128)\n",
    "        self.fc2 = nn.Linear(128, n_classes)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.relu(self.conv1(x)))  # [B,16,32,32]\n",
    "        x = self.pool(self.relu(self.conv2(x)))  # [B,32,16,16]\n",
    "        x = self.pool(self.relu(self.conv3(x)))  # [B,64,8,8]\n",
    "        x = x.view(-1, 64 * 8 * 8)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.sigmoid(self.fc2(x))\n",
    "        return x\n",
    "\n",
    "class ResNetSpec(nn.Module):\n",
    "    \"\"\"ResNet‑34 backbone adapted for single‑channel spectrogram input.\"\"\"\n",
    "    def __init__(self, n_classes=11):\n",
    "        super().__init__()\n",
    "        self.backbone = resnet34(weights=None)\n",
    "        self.backbone.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        # Replace FC\n",
    "        self.backbone.fc = nn.Sequential(\n",
    "            nn.Linear(self.backbone.fc.in_features, n_classes),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.backbone(x)\n",
    "\n",
    "# Display model architectures\n",
    "print(\"CNN Baseline Architecture:\")\n",
    "print(CNNBaseline())\n",
    "print(\"\\nResNet Architecture:\")\n",
    "print(ResNetSpec())\n"
   ],
   "id": "984567832a6a1ef9",
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "CNN Baseline Architecture:\n",
      "CNNBaseline(\n",
      "  (conv1): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=4096, out_features=128, bias=True)\n",
      "  (fc2): Linear(in_features=128, out_features=11, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n",
      "\n",
      "ResNet Architecture:\n",
      "ResNetSpec(\n",
      "  (backbone): ResNet(\n",
      "    (conv1): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "    (layer1): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (2): BasicBlock(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (layer2): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (2): BasicBlock(\n",
      "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (3): BasicBlock(\n",
      "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (layer3): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (2): BasicBlock(\n",
      "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (3): BasicBlock(\n",
      "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (4): BasicBlock(\n",
      "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (5): BasicBlock(\n",
      "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (layer4): Sequential(\n",
      "      (0): BasicBlock(\n",
      "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): BasicBlock(\n",
      "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (2): BasicBlock(\n",
      "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "    (fc): Sequential(\n",
      "      (0): Linear(in_features=512, out_features=11, bias=True)\n",
      "      (1): Sigmoid()\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ],
   "metadata": {
    "id": "7IpXiysDT_7f"
   },
   "id": "7IpXiysDT_7f",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "id": "1afd7ff405b60128"
   },
   "cell_type": "markdown",
   "source": [
    "## Define Dataset and DataLoader\n",
    "\n",
    "Let's define the dataset and dataloader for our project.\n"
   ],
   "id": "1afd7ff405b60128"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-31T09:28:06.408132Z",
     "start_time": "2025-05-31T09:28:04.942073Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "99f760797a7c31c8",
    "outputId": "09e4a73f-8c7c-4546-ba39-d6134d7914c2"
   },
   "cell_type": "code",
   "source": [
    "LABELS = [\"cello\", \"clarinet\", \"flute\", \"acoustic_guitar\", \"organ\", \"piano\", \"saxophone\", \"trumpet\", \"violin\", \"voice\", \"other\"]\n",
    "\n",
    "def pad_collate(batch):\n",
    "    xs, ys = zip(*batch)\n",
    "    # find max mel bins in batch\n",
    "    H = max(x.shape[1] for x in xs)\n",
    "    W = max(x.shape[2] for x in xs)      # optional time padding\n",
    "    padded = []\n",
    "    for x in xs:\n",
    "        pad_h = H - x.shape[1]\n",
    "        pad_w = W - x.shape[2]\n",
    "        x_padded = torch.nn.functional.pad(x, (0, pad_w, 0, pad_h))  # (left, right, top, bottom)\n",
    "        padded.append(x_padded)\n",
    "    return torch.stack(padded), torch.stack(ys)\n",
    "\n",
    "class NpyDataset(Dataset):\n",
    "    def __init__(self, root):\n",
    "        self.files = list(pathlib.Path(root).rglob(\"*.npy\"))\n",
    "        self.label_map = {label: i for i, label in enumerate(LABELS)}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        spec = np.load(self.files[idx])\n",
    "        x = torch.tensor(spec).unsqueeze(0)  # [1,H,W]\n",
    "\n",
    "        # Parse label from folder name\n",
    "        label_str = self.files[idx].parent.name.split(\"_\")[0]\n",
    "        y = torch.zeros(len(LABELS))\n",
    "\n",
    "        # Map label string to index\n",
    "        if label_str in self.label_map:\n",
    "            y[self.label_map[label_str]] = 1.0\n",
    "\n",
    "        return x, y\n",
    "\n",
    "# Create datasets and dataloaders\n",
    "train_ds = NpyDataset(\"data/processed/train\")\n",
    "val_ds = NpyDataset(\"data/processed/val\")\n",
    "\n",
    "print(f\"Training dataset size: {len(train_ds)}\")\n",
    "print(f\"Validation dataset size: {len(val_ds)}\")\n",
    "\n",
    "# Create dataloaders\n",
    "train_loader = DataLoader(train_ds, batch_size=resnet_cfg['batch_size'], shuffle=True, num_workers=resnet_cfg['num_workers'], collate_fn=pad_collate)\n",
    "val_loader = DataLoader(val_ds, batch_size=resnet_cfg['batch_size'], shuffle=False, num_workers=resnet_cfg['num_workers'], collate_fn=pad_collate)\n"
   ],
   "id": "99f760797a7c31c8",
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training dataset size: 54306\n",
      "Validation dataset size: 6039\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {
    "id": "51bed2a43f59dc9f"
   },
   "cell_type": "markdown",
   "source": [
    "## Define Model\n",
    "\n",
    "Let's define the model for our project.\n"
   ],
   "id": "51bed2a43f59dc9f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-31T09:28:09.439064Z",
     "start_time": "2025-05-31T09:28:08.661393Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 367
    },
    "id": "8a27dfacdefe25b1",
    "outputId": "9fa72f09-2e18-419a-f3d3-498f2c5dce23"
   },
   "cell_type": "code",
   "source": [
    "from torchmetrics import Accuracy, Precision, Recall, F1Score\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# 1. Metrics collection that knows its target device\n",
    "# -----------------------------------------------------------\n",
    "class MetricCollection:\n",
    "    def __init__(self, n_classes: int, device: torch.device | str = \"cpu\"):\n",
    "        self.accuracy  = Accuracy(task=\"multilabel\",  num_labels=n_classes).to(device)\n",
    "        self.precision = Precision(task=\"multilabel\", num_labels=n_classes).to(device)\n",
    "        self.recall    = Recall(task=\"multilabel\",    num_labels=n_classes).to(device)\n",
    "        self.f1        = F1Score(task=\"multilabel\",   num_labels=n_classes).to(device)\n",
    "\n",
    "    def __call__(self, preds: torch.Tensor, targets: torch.Tensor) -> dict:\n",
    "        return {\n",
    "            \"accuracy\":  self.accuracy(preds, targets),\n",
    "            \"precision\": self.precision(preds, targets),\n",
    "            \"recall\":    self.recall(preds, targets),\n",
    "            \"f1\":        self.f1(preds, targets),\n",
    "        }\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# 2. Model wrapper\n",
    "# -----------------------------------------------------------\n",
    "class InstrumentModel(nn.Module):\n",
    "    def __init__(self, cfg: dict):\n",
    "        super().__init__()\n",
    "        n_classes = len(LABELS)\n",
    "        backbone  = ResNetSpec if cfg.get(\"model_name\", \"cnn\") == \"resnet34\" else CNNBaseline\n",
    "        self.model   = backbone(n_classes)\n",
    "        self.device_ = torch.device(cfg.get(\"device\", \"cpu\"))\n",
    "        self.metrics = MetricCollection(n_classes, device=self.device_)\n",
    "        self.lr      = float(cfg.get(\"learning_rate\", 1e-4))\n",
    "\n",
    "    # ---- forward / training utils ----------------------------------------\n",
    "    def forward(self, x):                       # x on self.device_\n",
    "        return self.model(x)\n",
    "\n",
    "    def compute_loss_and_metrics(self, batch, stage=\"train\"):\n",
    "        x, y  = (t.to(self.device_) for t in batch)   # ensure batch on same device\n",
    "        preds = self(x)\n",
    "        loss  = torch.nn.functional.binary_cross_entropy(preds, y)\n",
    "        return loss, self.metrics(preds, y), preds\n",
    "\n",
    "    def get_optimizer(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=self.lr)\n",
    "\n",
    "# -----------------------------------------------------------\n",
    "# 3. Instantiate on the desired device BEFORE training loop\n",
    "# -----------------------------------------------------------\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "resnet_cfg[\"device\"] = str(device)               # make sure cfg knows the device\n",
    "\n",
    "model = InstrumentModel(resnet_cfg).to(device)   # moves model **and** its metrics\n",
    "print(f\"Model initialised on {device}\")"
   ],
   "id": "8a27dfacdefe25b1",
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'MultilabelF1Score' is not defined",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-12-4b429abec57f>\u001B[0m in \u001B[0;36m<cell line: 0>\u001B[0;34m()\u001B[0m\n\u001B[1;32m     45\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     46\u001B[0m \u001B[0;31m# Initialize model\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 47\u001B[0;31m \u001B[0mmodel\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mInstrumentModel\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mresnet_cfg\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     48\u001B[0m \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"Model initialized with ResNet-34 backbone\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<ipython-input-12-4b429abec57f>\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self, cfg)\u001B[0m\n\u001B[1;32m     28\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcfg\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcfg\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     29\u001B[0m         \u001B[0mn_labels\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;36m11\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 30\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mf1_metric\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mMultilabelF1Score\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mnum_labels\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mn_labels\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mto\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcfg\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'device'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m  \u001B[0;31m# ← add .to(...)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     31\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     32\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'MultilabelF1Score' is not defined"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "id": "7f5bd5524c70d2dd"
   },
   "cell_type": "markdown",
   "source": [
    "## Train Model\n",
    "\n",
    "Let's train the model using PyTorch.\n"
   ],
   "id": "7f5bd5524c70d2dd"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-31T09:32:00.169657Z",
     "start_time": "2025-05-31T09:28:12.830537Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 723
    },
    "id": "4555865f5474b858",
    "outputId": "ceace94e-8bd9-42ce-9cc0-d7260758602f"
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Create directories for saving models\n",
    "os.makedirs('checkpoints', exist_ok=True)\n",
    "\n",
    "class EarlyStopping:\n",
    "    \"\"\"Custom implementation of early stopping\"\"\"\n",
    "    def __init__(self, patience=5, mode='max', min_delta=0):\n",
    "        self.patience = patience\n",
    "        self.mode = mode\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "\n",
    "    def __call__(self, score):\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            return False\n",
    "\n",
    "        if self.mode == 'max':\n",
    "            if score > self.best_score + self.min_delta:\n",
    "                self.best_score = score\n",
    "                self.counter = 0\n",
    "            else:\n",
    "                self.counter += 1\n",
    "        else:  # mode == 'min'\n",
    "            if score < self.best_score - self.min_delta:\n",
    "                self.best_score = score\n",
    "                self.counter = 0\n",
    "            else:\n",
    "                self.counter += 1\n",
    "\n",
    "        if self.counter >= self.patience:\n",
    "            self.early_stop = True\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "def train_model(model, train_loader, val_loader, num_epochs, device='cuda' if torch.cuda.is_available() else 'cpu'):\n",
    "    \"\"\"Train the model using standard PyTorch training loop\"\"\"\n",
    "    model = model.to(device)\n",
    "    optimizer = model.get_optimizer()\n",
    "\n",
    "    # Initialize early stopping\n",
    "    early_stopping = EarlyStopping(patience=5, mode='max')\n",
    "\n",
    "    # Initialize best model tracking\n",
    "    best_f1 = 0.0\n",
    "    best_model_path = None\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        train_metrics = {}\n",
    "\n",
    "        progress_bar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs} [Train]')\n",
    "        for batch in progress_bar:\n",
    "            # Move batch to device\n",
    "            batch = [x.to(device) for x in batch]\n",
    "\n",
    "            # Zero gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass, compute loss and metrics\n",
    "            loss, metrics, _ = model.compute_loss_and_metrics(batch, stage='train')\n",
    "\n",
    "            # Backward pass and optimize\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Update metrics\n",
    "            train_loss += loss.item()\n",
    "            for k, v in metrics.items():\n",
    "                if k not in train_metrics:\n",
    "                    train_metrics[k] = 0.0\n",
    "                train_metrics[k] += v.item()\n",
    "\n",
    "            # Update progress bar\n",
    "            progress_bar.set_postfix({\n",
    "                'loss': loss.item(),\n",
    "                'f1': metrics['f1'].item()\n",
    "            })\n",
    "\n",
    "        # Compute average metrics for the epoch\n",
    "        train_loss /= len(train_loader)\n",
    "        for k in train_metrics:\n",
    "            train_metrics[k] /= len(train_loader)\n",
    "\n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_metrics = {}\n",
    "\n",
    "        with torch.no_grad():\n",
    "            progress_bar = tqdm(val_loader, desc=f'Epoch {epoch+1}/{num_epochs} [Val]')\n",
    "            for batch in progress_bar:\n",
    "                # Move batch to device\n",
    "                batch = [x.to(device) for x in batch]\n",
    "\n",
    "                # Forward pass, compute loss and metrics\n",
    "                loss, metrics, _ = model.compute_loss_and_metrics(batch, stage='val')\n",
    "\n",
    "                # Update metrics\n",
    "                val_loss += loss.item()\n",
    "                for k, v in metrics.items():\n",
    "                    if k not in val_metrics:\n",
    "                        val_metrics[k] = 0.0\n",
    "                    val_metrics[k] += v.item()\n",
    "\n",
    "                # Update progress bar\n",
    "                progress_bar.set_postfix({\n",
    "                    'loss': loss.item(),\n",
    "                    'f1': metrics['f1'].item()\n",
    "                })\n",
    "\n",
    "        # Compute average metrics for the epoch\n",
    "        val_loss /= len(val_loader)\n",
    "        for k in val_metrics:\n",
    "            val_metrics[k] /= len(val_loader)\n",
    "\n",
    "        # Print epoch summary\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}:')\n",
    "        print(f'  Train Loss: {train_loss:.4f}, F1: {train_metrics[\"f1\"]:.4f}')\n",
    "        print(f'  Val Loss: {val_loss:.4f}, F1: {val_metrics[\"f1\"]:.4f}')\n",
    "\n",
    "        # Save best model\n",
    "        if val_metrics['f1'] > best_f1:\n",
    "            best_f1 = val_metrics['f1']\n",
    "            best_model_path = f'checkpoints/best-{epoch+1:02d}-{val_metrics[\"f1\"]:.2f}.pt'\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'val_f1': val_metrics['f1'],\n",
    "                'val_loss': val_loss\n",
    "            }, best_model_path)\n",
    "            print(f'  Saved best model to {best_model_path}')\n",
    "\n",
    "        # Check early stopping\n",
    "        if early_stopping(val_metrics['f1']):\n",
    "            print(f'Early stopping triggered after {epoch+1} epochs')\n",
    "            break\n",
    "\n",
    "    # Load best model\n",
    "    if best_model_path:\n",
    "        checkpoint = torch.load(best_model_path)\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        print(f'Loaded best model from {best_model_path} with F1: {checkpoint[\"val_f1\"]:.4f}')\n",
    "\n",
    "    return model\n",
    "\n",
    "# Train model\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Using device: {device}\")\n",
    "model = train_model(model, train_loader, val_loader, num_epochs=resnet_cfg['num_epochs'], device=device)\n"
   ],
   "id": "4555865f5474b858",
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\rEpoch 1/50 [Train]:   0%|          | 0/3395 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:626: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n",
      "Epoch 1/50 [Train]:   0%|          | 0/3395 [00:02<?, ?it/s]\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "RuntimeError",
     "evalue": "Encountered different devices in metric calculation (see stacktrace for details). This could be due to the metric class not being on the same device as input. Instead of `metric=MultilabelAccuracy(...)` try to do `metric=MultilabelAccuracy(...).to(device)` where device corresponds to the device of the input.",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "\u001B[0;32m/usr/local/lib/python3.11/dist-packages/torchmetrics/metric.py\u001B[0m in \u001B[0;36mwrapped_func\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    548\u001B[0m                 \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 549\u001B[0;31m                     \u001B[0mupdate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    550\u001B[0m                 \u001B[0;32mexcept\u001B[0m \u001B[0mRuntimeError\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0merr\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.11/dist-packages/torchmetrics/classification/stat_scores.py\u001B[0m in \u001B[0;36mupdate\u001B[0;34m(self, preds, target)\u001B[0m\n\u001B[1;32m    496\u001B[0m         \u001B[0mtp\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfp\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtn\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfn\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_multilabel_stat_scores_update\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpreds\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtarget\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmultidim_average\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 497\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_update_state\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtp\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfp\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtn\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfn\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    498\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.11/dist-packages/torchmetrics/classification/stat_scores.py\u001B[0m in \u001B[0;36m_update_state\u001B[0;34m(self, tp, fp, tn, fn)\u001B[0m\n\u001B[1;32m     76\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 77\u001B[0;31m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtp\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtp\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0mtp\u001B[0m \u001B[0;32mif\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0misinstance\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtp\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlist\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32melse\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtp\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtp\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     78\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfp\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfp\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0mfp\u001B[0m \u001B[0;32mif\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0misinstance\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfp\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlist\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32melse\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfp\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfp\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mRuntimeError\u001B[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-11-d800944af8ab>\u001B[0m in \u001B[0;36m<cell line: 0>\u001B[0;34m()\u001B[0m\n\u001B[1;32m    156\u001B[0m \u001B[0mdevice\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m'cuda'\u001B[0m \u001B[0;32mif\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcuda\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mis_available\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32melse\u001B[0m \u001B[0;34m'cpu'\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    157\u001B[0m \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34mf\"Using device: {device}\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 158\u001B[0;31m \u001B[0mmodel\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtrain_model\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmodel\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtrain_loader\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mval_loader\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnum_epochs\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mresnet_cfg\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'num_epochs'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdevice\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mdevice\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m<ipython-input-11-d800944af8ab>\u001B[0m in \u001B[0;36mtrain_model\u001B[0;34m(model, train_loader, val_loader, num_epochs, device)\u001B[0m\n\u001B[1;32m     66\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     67\u001B[0m             \u001B[0;31m# Forward pass, compute loss and metrics\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 68\u001B[0;31m             \u001B[0mloss\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmetrics\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0m_\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mmodel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcompute_loss_and_metrics\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mbatch\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mstage\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m'train'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     69\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     70\u001B[0m             \u001B[0;31m# Backward pass and optimize\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<ipython-input-10-4378c50bb7fe>\u001B[0m in \u001B[0;36mcompute_loss_and_metrics\u001B[0;34m(self, batch, stage)\u001B[0m\n\u001B[1;32m     35\u001B[0m         \u001B[0mpreds\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     36\u001B[0m         \u001B[0mloss\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mnn\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfunctional\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbinary_cross_entropy\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpreds\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 37\u001B[0;31m         \u001B[0mmetrics\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmetrics\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpreds\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     38\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mloss\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmetrics\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mpreds\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     39\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<ipython-input-10-4378c50bb7fe>\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, preds, targets)\u001B[0m\n\u001B[1;32m     10\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m__call__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mpreds\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtargets\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     11\u001B[0m         return {\n\u001B[0;32m---> 12\u001B[0;31m             \u001B[0;34m\"accuracy\"\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0maccuracy\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpreds\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtargets\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     13\u001B[0m             \u001B[0;34m\"precision\"\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mprecision\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpreds\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtargets\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     14\u001B[0m             \u001B[0;34m\"recall\"\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrecall\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpreds\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtargets\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1749\u001B[0m             \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_compiled_call_impl\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m  \u001B[0;31m# type: ignore[misc]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1750\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1751\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_call_impl\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1752\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1753\u001B[0m     \u001B[0;31m# torchrec tests the code consistency with the following code\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1760\u001B[0m                 \u001B[0;32mor\u001B[0m \u001B[0m_global_backward_pre_hooks\u001B[0m \u001B[0;32mor\u001B[0m \u001B[0m_global_backward_hooks\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1761\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[0;32m-> 1762\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1763\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1764\u001B[0m         \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.11/dist-packages/torchmetrics/metric.py\u001B[0m in \u001B[0;36mforward\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    313\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_forward_cache\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_forward_full_state_update\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    314\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 315\u001B[0;31m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_forward_cache\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_forward_reduce_state_update\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    316\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    317\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_forward_cache\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.11/dist-packages/torchmetrics/metric.py\u001B[0m in \u001B[0;36m_forward_reduce_state_update\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    382\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    383\u001B[0m         \u001B[0;31m# calculate batch state and compute batch value\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 384\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mupdate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    385\u001B[0m         \u001B[0mbatch_val\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcompute\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    386\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.11/dist-packages/torchmetrics/metric.py\u001B[0m in \u001B[0;36mwrapped_func\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    550\u001B[0m                 \u001B[0;32mexcept\u001B[0m \u001B[0mRuntimeError\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0merr\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    551\u001B[0m                     \u001B[0;32mif\u001B[0m \u001B[0;34m\"Expected all tensors to be on\"\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mstr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0merr\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 552\u001B[0;31m                         raise RuntimeError(\n\u001B[0m\u001B[1;32m    553\u001B[0m                             \u001B[0;34m\"Encountered different devices in metric calculation (see stacktrace for details).\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    554\u001B[0m                             \u001B[0;34m\" This could be due to the metric class not being on the same device as input.\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mRuntimeError\u001B[0m: Encountered different devices in metric calculation (see stacktrace for details). This could be due to the metric class not being on the same device as input. Instead of `metric=MultilabelAccuracy(...)` try to do `metric=MultilabelAccuracy(...).to(device)` where device corresponds to the device of the input."
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {
    "id": "e31c78a534b9f07a"
   },
   "cell_type": "markdown",
   "source": [
    "## Inference\n",
    "\n",
    "Let's perform inference on a sample audio file.\n"
   ],
   "id": "e31c78a534b9f07a"
  },
  {
   "metadata": {
    "id": "bc6dba6ebb058133"
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def extract_features(path, cfg):\n",
    "    y, sr = librosa.load(path, sr=cfg['sample_rate'], mono=True)\n",
    "    specs_dict = generate_multi_stft(y, sr)\n",
    "\n",
    "    # For inference, we'll use the middle frequency band (1000-4000Hz) with the middle FFT size (512)\n",
    "    # This is a simplification - in a real application, you might want to use all bands and FFT sizes\n",
    "    key = (\"1000-4000Hz\", 512)\n",
    "    if key in specs_dict:\n",
    "        spec = specs_dict[key]\n",
    "        return torch.tensor(spec).unsqueeze(0).unsqueeze(0)\n",
    "    else:\n",
    "        # Fallback to the first available spectrogram if the preferred one is not available\n",
    "        first_key = list(specs_dict.keys())[0]\n",
    "        spec = specs_dict[first_key]\n",
    "        return torch.tensor(spec).unsqueeze(0).unsqueeze(0)\n",
    "\n",
    "def predict(model, wav_path, cfg):\n",
    "    model.eval()\n",
    "    x = extract_features(wav_path, cfg)\n",
    "    with torch.no_grad():\n",
    "        preds = model(x).squeeze().numpy()\n",
    "    return {label: float(preds[i]) for i, label in enumerate(LABELS)}\n",
    "\n",
    "# Get a sample WAV file for inference\n",
    "sample_wav = list(pathlib.Path('data/raw/IRMAS').rglob(\"*.wav\"))[0]\n",
    "print(f\"Sample WAV file: {sample_wav}\")\n",
    "\n",
    "# Perform inference\n",
    "results = predict(model, sample_wav, resnet_cfg)\n",
    "\n",
    "# Display results\n",
    "print(\"\\nPrediction results:\")\n",
    "for instrument, confidence in sorted(results.items(), key=lambda x: x[1], reverse=True):\n",
    "    print(f\"{instrument}: {confidence:.4f}\")\n",
    "\n",
    "# Visualize results\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(results.keys(), results.values())\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.ylabel('Confidence')\n",
    "plt.title('Instrument Detection Confidence')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ],
   "id": "bc6dba6ebb058133"
  },
  {
   "metadata": {
    "id": "f001ab5382f7830c"
   },
   "cell_type": "markdown",
   "source": [
    "## Visualize Audio and Spectrogram\n",
    "\n",
    "Let's visualize the audio waveform and spectrogram of the sample file.\n"
   ],
   "id": "f001ab5382f7830c"
  },
  {
   "metadata": {
    "id": "87142759197376f3"
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def visualize_audio(wav_path, cfg):\n",
    "    # Load audio\n",
    "    y, sr = librosa.load(wav_path, sr=cfg['sample_rate'], mono=True)\n",
    "\n",
    "    # Compute multi-band STFT spectrograms\n",
    "    specs_dict = generate_multi_stft(y, sr)\n",
    "\n",
    "    # Plot waveform and selected spectrograms\n",
    "    plt.figure(figsize=(15, 12))\n",
    "\n",
    "    # Plot waveform\n",
    "    plt.subplot(4, 1, 1)\n",
    "    librosa.display.waveshow(y, sr=sr)\n",
    "    plt.title('Waveform')\n",
    "\n",
    "    # Select three spectrograms to visualize (one from each frequency band with the middle FFT size)\n",
    "    keys_to_plot = [\n",
    "        (\"0-1000Hz\", 512),\n",
    "        (\"1000-4000Hz\", 512),\n",
    "        (\"4000-11025Hz\", 512)\n",
    "    ]\n",
    "\n",
    "    for i, key in enumerate(keys_to_plot):\n",
    "        if key in specs_dict:\n",
    "            plt.subplot(4, 1, i+2)\n",
    "            spec = specs_dict[key]\n",
    "            hop_length = 512 // 4  # hop_length for FFT size 512\n",
    "            librosa.display.specshow(spec, sr=sr, x_axis='time', hop_length=hop_length)\n",
    "            plt.colorbar(format='%+2.0f dB')\n",
    "            plt.title(f'Spectrogram: {key[0]}, FFT size: {key[1]}')\n",
    "        else:\n",
    "            print(f\"Spectrogram for {key} not found\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Visualize sample audio\n",
    "visualize_audio(sample_wav, resnet_cfg)\n"
   ],
   "id": "87142759197376f3"
  },
  {
   "metadata": {
    "id": "6f4b8dab8b5e35fe"
   },
   "cell_type": "markdown",
   "source": [
    "## Conclusion\n",
    "\n",
    "In this notebook, we've demonstrated the complete pipeline for multi-label musical instrument recognition:\n",
    "\n",
    "1. Setting up the environment\n",
    "2. Downloading and preprocessing the IRMAS dataset\n",
    "3. Defining and training a ResNet-34 model\n",
    "4. Performing inference on audio files\n",
    "5. Visualizing the results\n",
    "\n",
    "This notebook can be run in Google Colab without any special modifications to the codebase."
   ],
   "id": "6f4b8dab8b5e35fe"
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "language_info": {
   "name": "python"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
