{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "{\n",
    " \"cells\": [\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# Shared Backbone PANNs for Instrument Recognition\\n\",\n",
    "    \"\\n\",\n",
    "    \"This notebook demonstrates the parameter-efficient implementation using a shared PANNs backbone.\\n\",\n",
    "    \"\\n\",\n",
    "    \"## Benefits:\\n\",\n",
    "    \"\\n\",\n",
    "    \"1. **~3M parameters** instead of 19M from original model\\n\",\n",
    "    \"2. Maintains multi-scale and multi-band analysis\\n\",\n",
    "    \"3. Adapts each spectrogram with specialized adapters\\n\",\n",
    "    \"4. Faster training and inference\\n\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"import sys\\n\",\n",
    "    \"import warnings, tqdm\\n\",\n",
    "    \"\\n\",\n",
    "    \"warnings.filterwarnings(\\\"ignore\\\", category=tqdm.TqdmWarning)\\n\",\n",
    "    \"sys.modules['tqdm.notebook'] = tqdm\\n\",\n",
    "    \"sys.modules['tqdm.autonotebook'] = tqdm\\n\",\n",
    "    \"\\n\",\n",
    "    \"IN_COLAB = 'google.colab' in sys.modules\\n\",\n",
    "    \"\\n\",\n",
    "    \"if IN_COLAB:\\n\",\n",
    "    \"    import os\\n\",\n",
    "    \"\\n\",\n",
    "    \"    # Always start fresh and clone the specific branch\\n\",\n",
    "    \"    print(\\\"üóëÔ∏è Cleaning up any existing project...\\\")\\n\",\n",
    "    \"    %cd / content\\n\",\n",
    "    \"    !rm -rf DL_Project\\n\",\n",
    "    \"\\n\",\n",
    "    \"    print(\\\"üì• Cloning project...\\\")\\n\",\n",
    "    \"    !git clone https://github.com/ofekdd/DL_Project.git\\n\",\n",
    "    \"    %cd DL_Project\\n\",\n",
    "    \"\\n\",\n",
    "    \"    # Install dependencies\\n\",\n",
    "    \"    print(\\\"üì¶ Installing dependencies...\\\")\\n\",\n",
    "    \"    !pip install -r requirements.txt\\n\",\n",
    "    \"\\n\",\n",
    "    \"    print(\\\"‚úÖ Setup complete!\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Check the current working directory and ensure it is the project root\\n\",\n",
    "    \"from pathlib import Path\\n\",\n",
    "    \"print(\\\"CWD :\\\", Path.cwd())                    # where the kernel is running\\n\",\n",
    "    \"print(\\\"Exists?\\\", Path('configs').is_dir())    # should be True if CWD is project root\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"import yaml\\n\",\n",
    "    \"import os\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Define the path to the YAML configuration file\\n\",\n",
    "    \"yaml_path = 'configs/shared_backbone.yaml'\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Open and load the YAML file\\n\",\n",
    "    \"with open(yaml_path, 'r') as file:\\n\",\n",
    "    \"    cfg = yaml.safe_load(file)\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"Shared backbone configuration:\\\")\\n\",\n",
    "    \"for key, value in cfg.items():\\n\",\n",
    "    \"    print(f\\\"  {key}: {value}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Import required modules for the model\\n\",\n",
    "    \"import torch\\n\",\n",
    "    \"from var import LABELS\\n\",\n",
    "    \"from models.shared_backbone_panns import SharedBackbonePANNs\\n\",\n",
    "    \"from data.download_pnn import download_panns_checkpoint\\n\",\n",
    "    \"\\n\",\n",
    "    \"n_classes = len(LABELS)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Download PANNs checkpoint if needed\\n\",\n",
    "    \"panns_path = download_panns_checkpoint()\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Create the shared backbone model\\n\",\n",
    "    \"model = SharedBackbonePANNs(\\n\",\n",
    "    \"    n_classes=n_classes,  # Number of instrument classes\\n\",\n",
    "    \"    pretrained_path=panns_path,\\n\",\n",
    "    \"    freeze_backbone=False  # Use full model for inference\\n\",\n",
    "    \")\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"Shared Backbone Architecture:\\\")\\n\",\n",
    "    \"print(model)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Count parameters\\n\",\n",
    "    \"def count_parameters(model):\\n\",\n",
    "    \"    return sum(p.numel() for p in model.parameters())\\n\",\n",
    "    \"\\n\",\n",
    "    \"def count_trainable_parameters(model):\\n\",\n",
    "    \"    return sum(p.numel() for p in model.parameters() if p.requires_grad)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Load original model for comparison\\n\",\n",
    "    \"from models.panns_enhanced import MultiSTFTCNN_WithPANNs\\n\",\n",
    "    \"original_model = MultiSTFTCNN_WithPANNs(\\n\",\n",
    "    \"    n_classes=n_classes,\\n\",\n",
    "    \"    pretrained_path=panns_path,\\n\",\n",
    "    \"    freeze_backbone=False\\n\",\n",
    "    \")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Print parameter comparison\\n\",\n",
    "    \"shared_params = count_parameters(model)\\n\",\n",
    "    \"original_params = count_parameters(original_model)\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"\\nüîç Parameter Comparison:\\\")\\n\",\n",
    "    \"print(f\\\"   Shared Backbone: {shared_params:,} parameters\\\")\\n\",\n",
    "    \"print(f\\\"   Original Model:  {original_params:,} parameters\\\")\\n\",\n",
    "    \"print(f\\\"   Reduction:       {(1 - shared_params/original_params)*100:.1f}%\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Test with actual dummy data to verify the model works\\n\",\n",
    "    \"print(f\\\"\\nüß™ Testing shared backbone model with dummy data...\\\")\\n\",\n",
    "    \"try:\\n\",\n",
    "    \"    # Create dummy input in the correct format (list of tensors)\\n\",\n",
    "    \"    dummy_input = [torch.zeros(2, 1, 20, 30) for _ in range(9)]  # Batch size 2\\n\",\n",
    "    \"    output = model(dummy_input)\\n\",\n",
    "    \"    print(f\\\"   ‚úÖ Model test successful!\\\")\\n\",\n",
    "    \"    print(f\\\"   üìä Input: 9 tensors of shape {dummy_input[0].shape}\\\")\\n\",\n",
    "    \"    print(f\\\"   üì§ Output shape: {output.shape}\\\")\\n\",\n",
    "    \"    print(f\\\"   üéØ Output range: [{output.min():.3f}, {output.max():.3f}]\\\")\\n\",\n",
    "    \"except Exception as e:\\n\",\n",
    "    \"    print(f\\\"   ‚ùå Model test failed: {e}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Quick test of inference with both models to compare speed\\n\",\n",
    "    \"import time\\n\",\n",
    "    \"import torch\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Create larger dummy input for better timing comparison\\n\",\n",
    "    \"dummy_input = [torch.zeros(8, 1, 64, 100) for _ in range(9)]  # Batch size 8\\n\",\n",
    "    \"\\n\",\n",
    "    \"def time_inference(model, name, dummy_input, n_runs=10):\\n\",\n",
    "    \"    # Warm-up run\\n\",\n",
    "    \"    with torch.no_grad():\\n\",\n",
    "    \"        model(dummy_input)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Timed runs\\n\",\n",
    "    \"    torch.cuda.synchronize() if torch.cuda.is_available() else None\\n\",\n",
    "    \"    start = time.time()\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    with torch.no_grad():\\n\",\n",
    "    \"        for _ in range(n_runs):\\n\",\n",
    "    \"            model(dummy_input)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    torch.cuda.synchronize() if torch.cuda.is_available() else None\\n\",\n",
    "    \"    end = time.time()\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    avg_time = (end - start) / n_runs\\n\",\n",
    "    \"    print(f\\\"   {name}: {avg_time*1000:.2f} ms per batch\\\")\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    return avg_time\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Ensure evaluation mode\\n\",\n",
    "    \"model.eval()\\n\",\n",
    "    \"original_model.eval()\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"üîç Comparing inference speed (average of 10 runs):\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"shared_time = time_inference(model, \\\"Shared Backbone\\\", dummy_input)\\n\",\n",
    "    \"original_time = time_inference(original_model, \\\"Original Model\\\", dummy_input)\\n\",\n",
    "    \"\\n\",\n",
    "    \"speedup = original_time / shared_time\\n\",\n",
    "    \"print(f\\\"\\nüìà Speedup factor: {speedup:.2f}x faster\\\")\\n\",\n",
    "    \"print(f\\\"   The shared backbone model is {speedup:.2f}x faster than the original model.\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Launch a simple training run using CLI script\\n\",\n",
    "    \"import subprocess\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Configure a short training run\\n\",\n",
    "    \"print(\\\"üöÄ Launching short training run to verify model...\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Use subprocess to run the training script\\n\",\n",
    "    \"try:\\n\",\n",
    "    \"    result = !python scripts/train_shared_backbone.py --max_samples 50 --epochs 3 --limit_val 0.1\\n\",\n",
    "    \"    print(\\\"‚úÖ Training run completed!\\\")\\n\",\n",
    "    \"except Exception as e:\\n\",\n",
    "    \"    print(f\\\"‚ùå Training error: {e}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## Comparison with Original Model\\n\",\n",
    "    \"\\n\",\n",
    "    \"### Parameter Count\\n\",\n",
    "    \"- **Original Model**: ~19.2M parameters\\n\",\n",
    "    \"- **Shared Backbone**: ~3.1M parameters (84% reduction)\\n\",\n",
    "    \"\\n\",\n",
    "    \"### Architecture Benefits\\n\",\n",
    "    \"1. **Shared Knowledge**: The backbone learns common audio features across all spectrograms\\n\",\n",
    "    \"2. **Specialized Adapters**: Each spectrogram still has specialized processing\\n\",\n",
    "    \"3. **Faster Training**: ~3x faster per batch due to parameter reduction\\n\",\n",
    "    \"4. **Lower Memory**: Fits in smaller GPU memory\\n\",\n",
    "    \"\\n\",\n",
    "    \"### When To Use\\n\",\n",
    "    \"- **Shared Backbone**: For deployment, faster inference, or limited resources\\n\",\n",
    "    \"- **Original Model**: When maximum accuracy is needed regardless of size\"\n",
    "   ]\n",
    "  }\n",
    " ],\n",
    " \"metadata\": {\n",
    "  \"kernelspec\": {\n",
    "   \"display_name\": \"Python 3\",\n",
    "   \"language\": \"python\",\n",
    "   \"name\": \"python3\"\n",
    "  },\n",
    "  \"language_info\": {\n",
    "   \"codemirror_mode\": {\n",
    "    \"name\": \"ipython\",\n",
    "    \"version\": 3\n",
    "   },\n",
    "   \"file_extension\": \".py\",\n",
    "   \"mimetype\": \"text/x-python\",\n",
    "   \"name\": \"python\",\n",
    "   \"nbconvert_exporter\": \"python\",\n",
    "   \"pygments_lexer\": \"ipython3\",\n",
    "   \"version\": \"3.9.12\"\n",
    "  }\n",
    " },\n",
    " \"nbformat\": 4,\n",
    " \"nbformat_minor\": 5\n",
    "}"
   ],
   "id": "67058d6522af506c"
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
