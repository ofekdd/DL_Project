{
 "cells": [
  {
   "cell_type": "code",
   "id": "fae51c5c100772c5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-07T07:18:27.171955Z",
     "start_time": "2025-06-07T07:18:27.160441Z"
    }
   },
   "source": [
    "import sys\n",
    "import warnings, tqdm\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=tqdm.TqdmWarning)\n",
    "sys.modules['tqdm.notebook'] = tqdm\n",
    "sys.modules['tqdm.autonotebook'] = tqdm\n",
    "\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "\n",
    "if IN_COLAB:\n",
    "    # Clone the repository\n",
    "    !git clone https://github.com/ofekdd/DL_Project.git\n",
    "    %cd DL_Project\n",
    "\n",
    "    # Install dependencies\n",
    "    !pip install -r requirements.txt\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-07T07:18:27.238878Z",
     "start_time": "2025-06-07T07:18:27.232410Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Check the current working directory and ensure it is the project root\n",
    "from pathlib import Path\n",
    "print(\"CWD :\", Path.cwd())                    # where the kernel is running\n",
    "print(\"Exists?\", Path('configs').is_dir())    # should be True if CWD is project root\n"
   ],
   "id": "3d6ed40822d8c61b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CWD : /home/odahan/Technion/Semester_8/Deep_Learning/Project/notebooks\n",
      "Exists? False\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-07T07:18:27.301113Z",
     "start_time": "2025-06-07T07:18:27.291167Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import yaml\n",
    "import os\n",
    "\n",
    "# Define the path to the YAML configuration file\n",
    "workspace = '/home/odahan/Technion/Semester_8/Deep_Learning/Project'\n",
    "yaml_path = f'{workspace}/configs/multi_stft_cnn.yaml'\n",
    "print(yaml_path)\n",
    "# Open and load the YAML file\n",
    "with open(yaml_path, 'r') as file:\n",
    "    cfg = yaml.safe_load(file)\n",
    "\n",
    "print(\"9cnn configuration:\")\n",
    "for key, value in cfg.items():\n",
    "    print(f\"  {key}: {value}\")"
   ],
   "id": "4be9f8e58789698a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/odahan/Technion/Semester_8/Deep_Learning/Project/configs/multi_stft_cnn.yaml\n",
      "9cnn configuration:\n",
      "  model_name: multi_stft_cnn\n",
      "  sample_rate: 22050\n",
      "  n_mels: 64\n",
      "  hop_length: 512\n",
      "  batch_size: 8\n",
      "  num_epochs: 50\n",
      "  learning_rate: 2e-4\n",
      "  num_workers: 4\n",
      "  n_branches: 9\n",
      "  branch_output_dim: 128\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-07T07:19:33.884323Z",
     "start_time": "2025-06-07T07:18:27.376449Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Download the IRMAS dataset if needed\n",
    "from data.download_irmas import main as download_irmas_main, find_irmas_root\n",
    "import pathlib\n",
    "\n",
    "# Determine the appropriate download location based on environment\n",
    "if IN_COLAB:\n",
    "    # For Colab, use Google Drive to store the dataset (already mounted)\n",
    "    DATA_CACHE = \"/content/drive/MyDrive/datasets/IRMAS\"\n",
    "else:\n",
    "    # For local environment, store in the project directory\n",
    "    DATA_CACHE = \"data/raw\"\n",
    "\n",
    "# Create the directory if it doesn't exist\n",
    "os.makedirs(DATA_CACHE, exist_ok=True)\n",
    "\n",
    "# Download and extract the dataset\n",
    "print(f\"Downloading IRMAS dataset to {DATA_CACHE}...\")\n",
    "download_irmas_main(pathlib.Path(DATA_CACHE))\n",
    "\n",
    "# Find the IRMAS dataset root\n",
    "irmas_root = find_irmas_root()\n",
    "if irmas_root:\n",
    "    print(f\"IRMAS dataset found at: {irmas_root}\")\n",
    "\n",
    "    # Define the processing output directory\n",
    "    PROCESSED_DIR = \"/content/IRMAS_features\" if IN_COLAB else \"data/processed\"\n",
    "\n",
    "    # Suggest the next step\n",
    "    print(f\"\\nTo preprocess the data, you can run:\")\n",
    "    print(f\"python data/preprocess.py --in_dir {irmas_root} --out_dir {PROCESSED_DIR}\")\n",
    "\n",
    "    # Optional: Add a cell to automatically run preprocessing if needed\n",
    "    preprocess_cmd = f\"!python data/preprocess.py --in_dir {irmas_root} --out_dir {PROCESSED_DIR}\"\n",
    "    print(f\"\\nOr execute this command in the next cell:\")\n",
    "    print(preprocess_cmd)\n",
    "else:\n",
    "    print(\"Could not locate IRMAS dataset after download. Check paths and try again.\")"
   ],
   "id": "e96b51ebbb46946c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading IRMAS dataset to data/raw...\n",
      "Archive already exists, skipping download\n",
      "Verifying checksum ...\n",
      "Extracting ...\n",
      "Done. Data at data/raw\n",
      "IRMAS dataset found at: data/raw/IRMAS-TrainingData\n",
      "\n",
      "To preprocess the data, you can run:\n",
      "python data/preprocess.py --in_dir data/raw/IRMAS-TrainingData --out_dir data/processed\n",
      "\n",
      "Or execute this command in the next cell:\n",
      "!python data/preprocess.py --in_dir data/raw/IRMAS-TrainingData --out_dir data/processed\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-07T07:19:33.975694Z",
     "start_time": "2025-06-07T07:19:33.966876Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Check if preprocessing is needed and run the preprocessing step\n",
    "import os\n",
    "\n",
    "# Create the directory if it doesn't exist\n",
    "os.makedirs(PROCESSED_DIR, exist_ok=True)\n",
    "\n",
    "# Check if preprocessing is needed\n",
    "if irmas_root and not os.path.exists(f\"{PROCESSED_DIR}/train\") or len(os.listdir(f\"{PROCESSED_DIR}/train\")) == 0:\n",
    "    print(f\"Starting preprocessing from {irmas_root} to {PROCESSED_DIR}...\")\n",
    "\n",
    "    # Run the preprocessing command\n",
    "    !python data/preprocess.py --in_dir {irmas_root} --out_dir {PROCESSED_DIR} --config configs/default.yaml\n",
    "\n",
    "    print(f\"Preprocessing complete. Features saved to {PROCESSED_DIR}\")\n",
    "else:\n",
    "    print(f\"Processed data already exists at {PROCESSED_DIR} - skipping preprocessing\")"
   ],
   "id": "3b8e4f045c26a78c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data already exists at data/processed - skipping preprocessing\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-07T07:23:06.150747Z",
     "start_time": "2025-06-07T07:23:06.114009Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Import required modules for the model\n",
    "import torch\n",
    "from var import LABELS\n",
    "from models.multi_stft_cnn_with_stft import MultiSTFTCNN\n",
    "\n",
    "n_classes = len(LABELS)\n",
    "\n",
    "# Create the model\n",
    "model = MultiSTFTCNN(\n",
    "    n_classes=n_classes,  # Number of instrument classes\n",
    "    n_branches=9,  # 3 FFT sizes Ã— 3 frequency bands\n",
    "    branch_output_dim=128  # Default value for feature dimension\n",
    ")\n",
    "\n",
    "print(\"9 CNN Baseline Architecture:\")\n",
    "print(model)\n",
    "\n",
    "# Optional: Print model summary if torchinfo is available\n",
    "try:\n",
    "    from torchinfo import summary\n",
    "    # Create dummy input for the model (9 spectrograms with random dimensions)\n",
    "    dummy_input = [torch.zeros(1, 1, 20, 30) for _ in range(9)]\n",
    "    print(\"\\nModel Summary:\")\n",
    "    summary(model, input_data=dummy_input)\n",
    "except ImportError:\n",
    "    print(\"\\nInstall torchinfo for detailed model summary: pip install torchinfo\")"
   ],
   "id": "17f023b62a55eedb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 CNN Baseline Architecture:\n",
      "MultiSTFTCNN(\n",
      "  (branches): ModuleList(\n",
      "    (0-8): 9 x STFTBranch(\n",
      "      (cnn): Sequential(\n",
      "        (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU()\n",
      "        (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "        (4): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (6): ReLU()\n",
      "        (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "        (8): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (9): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (10): ReLU()\n",
      "        (11): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "        (12): Flatten(start_dim=1, end_dim=-1)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=1152, out_features=11, bias=True)\n",
      "    (1): Sigmoid()\n",
      "  )\n",
      ")\n",
      "\n",
      "Install torchinfo for detailed model summary: pip install torchinfo\n"
     ]
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-07T07:23:09.942300Z",
     "start_time": "2025-06-07T07:23:09.936246Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Set the number of samples to use for training\n",
    "# Set to None to use all samples, or a number (e.g., 50) to limit the samples\n",
    "max_samples = 30  # Change to a number like 50 to run with limited samples\n",
    "\n",
    "# Add max_samples to the configuration if it's not None\n",
    "if max_samples is not None:\n",
    "    cfg['max_samples'] = max_samples\n",
    "    print(f\"Training with limited samples: {max_samples}\")\n",
    "else:\n",
    "    print(\"Training with all available samples\")\n"
   ],
   "id": "11f0f267a4c9c98c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with limited samples: 30\n"
     ]
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-07T07:23:20.310616Z",
     "start_time": "2025-06-07T07:23:12.006924Z"
    }
   },
   "cell_type": "code",
   "source": [
    "try:\n",
    "    from training.train import main as train_main\n",
    "    train_main(cfg)\n",
    "    print(\"Training completed!\")\n",
    "except Exception as e:\n",
    "    print(f\"Error with direct import: {e}\")\n",
    "    print(\"Falling back to shell command\")\n",
    "    # If using shell command, we need to create a temporary config file with max_samples\n",
    "    if max_samples is not None:\n",
    "        import tempfile\n",
    "        import yaml\n",
    "\n",
    "        # Create a temporary config file with max_samples\n",
    "        temp_cfg_path = tempfile.mktemp(suffix='.yaml')\n",
    "        with open(temp_cfg_path, 'w') as temp_cfg:\n",
    "            yaml.dump(cfg, temp_cfg)\n",
    "\n",
    "        !python -m training.train --config {temp_cfg_path}\n",
    "\n",
    "        # Clean up the temporary file\n",
    "        import os\n",
    "        os.unlink(temp_cfg_path)\n",
    "    else:\n",
    "        !python -m training.train --config {yaml_path}"
   ],
   "id": "9d09f471df9d60b6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error with direct import: expected str, bytes or os.PathLike object, not dict\n",
      "Falling back to shell command\n",
      "GPU available: False, used: False\r\n",
      "TPU available: False, using: 0 TPU cores\r\n",
      "IPU available: False, using: 0 IPUs\r\n",
      "HPU available: False, using: 0 HPUs\r\n",
      "/home/odahan/Technion/Semester_8/Deep_Learning/Project/.venv/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/logger_connector/logger_connector.py:67: UserWarning: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `pytorch_lightning` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\r\n",
      "  warning_cache.warn(\r\n",
      "Missing logger folder: /home/odahan/Technion/Semester_8/Deep_Learning/Project/notebooks/lightning_logs\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"/usr/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\r\n",
      "    return _run_code(code, main_globals, None,\r\n",
      "  File \"/usr/lib/python3.9/runpy.py\", line 87, in _run_code\r\n",
      "    exec(code, run_globals)\r\n",
      "  File \"/home/odahan/Technion/Semester_8/Deep_Learning/Project/training/train.py\", line 71, in <module>\r\n",
      "    main(args.config)\r\n",
      "  File \"/home/odahan/Technion/Semester_8/Deep_Learning/Project/training/train.py\", line 65, in main\r\n",
      "    trainer.fit(model, train_loader, val_loader)\r\n",
      "  File \"/home/odahan/Technion/Semester_8/Deep_Learning/Project/.venv/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py\", line 520, in fit\r\n",
      "    call._call_and_handle_interrupt(\r\n",
      "  File \"/home/odahan/Technion/Semester_8/Deep_Learning/Project/.venv/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py\", line 44, in _call_and_handle_interrupt\r\n",
      "    return trainer_fn(*args, **kwargs)\r\n",
      "  File \"/home/odahan/Technion/Semester_8/Deep_Learning/Project/.venv/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py\", line 559, in _fit_impl\r\n",
      "    self._run(model, ckpt_path=ckpt_path)\r\n",
      "  File \"/home/odahan/Technion/Semester_8/Deep_Learning/Project/.venv/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py\", line 911, in _run\r\n",
      "    self.strategy.setup(self)\r\n",
      "  File \"/home/odahan/Technion/Semester_8/Deep_Learning/Project/.venv/lib/python3.9/site-packages/pytorch_lightning/strategies/single_device.py\", line 74, in setup\r\n",
      "    super().setup(trainer)\r\n",
      "  File \"/home/odahan/Technion/Semester_8/Deep_Learning/Project/.venv/lib/python3.9/site-packages/pytorch_lightning/strategies/strategy.py\", line 148, in setup\r\n",
      "    self.setup_optimizers(trainer)\r\n",
      "  File \"/home/odahan/Technion/Semester_8/Deep_Learning/Project/.venv/lib/python3.9/site-packages/pytorch_lightning/strategies/strategy.py\", line 138, in setup_optimizers\r\n",
      "    self.optimizers, self.lr_scheduler_configs = _init_optimizers_and_lr_schedulers(self.lightning_module)\r\n",
      "  File \"/home/odahan/Technion/Semester_8/Deep_Learning/Project/.venv/lib/python3.9/site-packages/pytorch_lightning/core/optimizer.py\", line 171, in _init_optimizers_and_lr_schedulers\r\n",
      "    optim_conf = call._call_lightning_module_hook(model.trainer, \"configure_optimizers\", pl_module=model)\r\n",
      "  File \"/home/odahan/Technion/Semester_8/Deep_Learning/Project/.venv/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py\", line 142, in _call_lightning_module_hook\r\n",
      "    output = fn(*args, **kwargs)\r\n",
      "  File \"/home/odahan/Technion/Semester_8/Deep_Learning/Project/training/train.py\", line 41, in configure_optimizers\r\n",
      "    return torch.optim.Adam(self.parameters(), lr=self.lr)\r\n",
      "  File \"/home/odahan/Technion/Semester_8/Deep_Learning/Project/.venv/lib/python3.9/site-packages/torch/optim/adam.py\", line 57, in __init__\r\n",
      "    if not 0.0 <= lr:\r\n",
      "TypeError: '<=' not supported between instances of 'float' and 'str'\r\n"
     ]
    }
   ],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-07T07:19:43.791858Z",
     "start_time": "2025-06-07T07:19:43.774535Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Quick inference + visualisation demo\n",
    "------------------------------------\n",
    "\n",
    "Example:\n",
    "    python inference_demo.py \\\n",
    "        --ckpt lightning_logs/version_0/checkpoints/epoch=4-step=1234.ckpt \\\n",
    "        --wav  data/raw/IRMAS/IRMAS-TestingData/0001.wav\n",
    "\"\"\"\n",
    "import argparse\n",
    "import yaml\n",
    "import torch\n",
    "\n",
    "# ---------- internal imports ----------\n",
    "from inference import predict as run_predict           # reuse the function in predict.py\n",
    "from models.multi_stft_cnn import MultiSTFTCNN\n",
    "from var import LABELS\n",
    "\n",
    "# Try both import styles depending on how the package is laid out\n",
    "try:\n",
    "    from visualization.visualization import visualize_audio\n",
    "except ImportError:\n",
    "    from visualization import visualize_audio\n",
    "# --------------------------------------\n",
    "\n",
    "\n",
    "def main(ckpt_path: str, wav_path: str, cfg_path: str = \"configs/multi_stft_cnn.yaml\") -> None:\n",
    "    # 1) load config\n",
    "    cfg = yaml.safe_load(open(cfg_path, \"r\"))\n",
    "\n",
    "    # 2) build & load model\n",
    "    model = MultiSTFTCNN(n_classes=len(LABELS))\n",
    "    state = torch.load(ckpt_path, map_location=\"cpu\")[\"state_dict\"]\n",
    "    model.load_state_dict(state)\n",
    "\n",
    "    # 3) run prediction\n",
    "    scores = run_predict(model, wav_path, cfg)\n",
    "    print(\"\\nPredicted class-probabilities:\")\n",
    "    for label, score in scores.items():\n",
    "        print(f\"  {label:<8} {score:>.4f}\")\n",
    "\n",
    "    # 4) visualise the same file\n",
    "    print(\"\\nRendering waveform & spectrograms â€¦\")\n",
    "    visualize_audio(wav_path, cfg)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser(description=\"Inference + visualisation demo\")\n",
    "    parser.add_argument(\"--ckpt\", required=True, help=\"Path to a .ckpt checkpoint\")\n",
    "    parser.add_argument(\"--wav\",  required=True, help=\"Path to an audio file (wav)\")\n",
    "    parser.add_argument(\"--config\", default=\"configs/multi_stft_cnn.yaml\",\n",
    "                        help=\"YAML config used during training\")\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    main(args.ckpt, args.wav, args.config)\n"
   ],
   "id": "d7b9c7f1da8a02ae",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] --ckpt CKPT --wav WAV [--config CONFIG]\n",
      "ipykernel_launcher.py: error: the following arguments are required: --ckpt, --wav\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001B[0;31mSystemExit\u001B[0m\u001B[0;31m:\u001B[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/odahan/Technion/Semester_8/Deep_Learning/Project/.venv/lib/python3.9/site-packages/IPython/core/interactiveshell.py:3558: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "execution_count": 34
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
