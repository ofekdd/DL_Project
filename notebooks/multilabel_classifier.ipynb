{
 "cells": [
  {
   "cell_type": "code",
   "id": "fae51c5c100772c5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-07T07:18:27.171955Z",
     "start_time": "2025-06-07T07:18:27.160441Z"
    }
   },
   "source": [
    "\n",
    "import sys\n",
    "import warnings, tqdm\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=tqdm.TqdmWarning)\n",
    "sys.modules['tqdm.notebook'] = tqdm\n",
    "sys.modules['tqdm.autonotebook'] = tqdm\n",
    "\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "\n",
    "if IN_COLAB:\n",
    "    import os\n",
    "\n",
    "    # Always start fresh and clone the specific branch\n",
    "    print(\"üóëÔ∏è Cleaning up any existing project...\")\n",
    "    %cd / content\n",
    "    !rm -rf DL_Project\n",
    "\n",
    "    #TODO: Fix the branch according to the latest changes\n",
    "    print(\"üì• Cloning specific branch 'master'...\")\n",
    "    !git clone -b master https://github.com/ofekdd/DL_Project.git\n",
    "    %cd DL_Project\n",
    "\n",
    "    # Verify we're on the correct branch\n",
    "    print(\"üîç Verifying branch...\")\n",
    "    !git branch\n",
    "    !git log --oneline -n 3\n",
    "\n",
    "    # Install dependencies\n",
    "    print(\"üì¶ Installing dependencies...\")\n",
    "    !pip install -r requirements.txt\n",
    "\n",
    "    print(\"‚úÖ Setup complete with branch 'master'!\")"
   ],
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-07T07:18:27.238878Z",
     "start_time": "2025-06-07T07:18:27.232410Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Check the current working directory and ensure it is the project root\n",
    "from pathlib import Path\n",
    "print(\"CWD :\", Path.cwd())                    # where the kernel is running\n",
    "print(\"Exists?\", Path('configs').is_dir())    # should be True if CWD is project root\n"
   ],
   "id": "3d6ed40822d8c61b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CWD : /home/odahan/Technion/Semester_8/Deep_Learning/Project/notebooks\n",
      "Exists? False\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-07T07:18:27.301113Z",
     "start_time": "2025-06-07T07:18:27.291167Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import yaml\n",
    "import os\n",
    "\n",
    "# Define the path to the YAML configuration file\n",
    "workspace = '/home/odahan/Technion/Semester_8/Deep_Learning/Project'\n",
    "yaml_path = 'configs/panns_enhanced.yaml' if IN_COLAB else f'{workspace}/configs/panns_enhanced.yaml'\n",
    "print(yaml_path)\n",
    "# Open and load the YAML file\n",
    "with open(yaml_path, 'r') as file:\n",
    "    cfg = yaml.safe_load(file)\n",
    "\n",
    "print(\"PANNs-enhanced configuration:\")\n",
    "for key, value in cfg.items():\n",
    "    print(f\"  {key}: {value}\")"
   ],
   "id": "4be9f8e58789698a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/odahan/Technion/Semester_8/Deep_Learning/Project/configs/multi_stft_cnn.yaml\n",
      "9cnn configuration:\n",
      "  model_name: multi_stft_cnn\n",
      "  sample_rate: 22050\n",
      "  n_mels: 64\n",
      "  hop_length: 512\n",
      "  batch_size: 8\n",
      "  num_epochs: 50\n",
      "  learning_rate: 2e-4\n",
      "  num_workers: 4\n",
      "  n_branches: 9\n",
      "  branch_output_dim: 128\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Download the IRMAS dataset if needed\n",
    "from data.download_irmas import main as download_irmas_main, find_irmas_root\n",
    "import pathlib\n",
    "import os\n",
    "\n",
    "# Check for existing dataset in user's home directory first\n",
    "home_dataset_path = pathlib.Path.home() / \"datasets\" / \"irmas\" / \"IRMAS.zip\"\n",
    "\n",
    "# Determine the appropriate download location based on environment\n",
    "if IN_COLAB:\n",
    "    # For Colab, use Google Drive to store the dataset (already mounted)\n",
    "    DATA_CACHE = \"/content/drive/MyDrive/datasets/IRMAS\"\n",
    "else:\n",
    "    # For local environment, check if dataset exists in home directory\n",
    "    if home_dataset_path.exists():\n",
    "        print(f\"Found existing dataset at {home_dataset_path}\")\n",
    "        DATA_CACHE = str(home_dataset_path.parent)\n",
    "    else:\n",
    "        # Fall back to project directory\n",
    "        DATA_CACHE = \"data/raw\"\n",
    "\n",
    "# Create the directory if it doesn't exist\n",
    "os.makedirs(DATA_CACHE, exist_ok=True)\n",
    "# Only download if we don't have the zip file already\n",
    "zip_path = pathlib.Path(DATA_CACHE) / \"IRMAS.zip\"\n",
    "if zip_path.exists():\n",
    "    print(f\"Dataset already exists at {zip_path}, skipping download...\")\n",
    "else:\n",
    "    print(f\"Downloading IRMAS dataset to {DATA_CACHE}...\")\n",
    "    download_irmas_main(pathlib.Path(DATA_CACHE))\n",
    "\n",
    "# Find the IRMAS dataset root\n",
    "irmas_root = find_irmas_root()\n",
    "print(f\"IRMAS root found at: {irmas_root}\")"
   ],
   "id": "6e04ee7069ac34ec",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Fix NumPy compatibility issue\n",
    "import sys\n",
    "\n",
    "print(\"üîß Fixing NumPy compatibility...\")\n",
    "\n",
    "# Check current NumPy version\n",
    "import numpy as np\n",
    "\n",
    "print(f\"Current NumPy version: {np.__version__}\")\n",
    "\n",
    "# If NumPy 2.0+, we need to downgrade or use a workaround\n",
    "if int(np.__version__.split('.')[0]) >= 2:\n",
    "    print(\"‚ö†Ô∏è  NumPy 2.0+ detected. Installing compatible version...\")\n",
    "    !pip install \"numpy<2.0\" --quiet\n",
    "\n",
    "    # Restart the kernel to load the new NumPy version\n",
    "    print(\"üîÑ Restarting kernel to load compatible NumPy...\")\n",
    "    import os\n",
    "\n",
    "    os.kill(os.getpid(), 9)  # This will restart the kernel in Colab\n",
    "else:\n",
    "    print(\"‚úÖ NumPy version is compatible\")"
   ],
   "id": "d9db882fdcb43259"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Convert the training dataset into multi-label format\n",
    "from data.mix_labels import create_multilabel_dataset\n",
    "\n",
    "if irmas_root:\n",
    "    print(\"Creating multi-label dataset from IRMAS...\")\n",
    "    print(f\"üìÅ Dataset creation settings from config:\")\n",
    "    print(f\"   max_original_samples: {cfg.get('max_original_samples', 50)}\")\n",
    "    print(f\"   num_mixtures: {cfg.get('num_mixtures', 100)}\")\n",
    "    print(f\"   min_instruments: {cfg.get('min_instruments', 1)}\")\n",
    "    print(f\"   max_instruments: {cfg.get('max_instruments', 2)}\")\n",
    "\n",
    "    # Fix the path issue\n",
    "    if irmas_root.name == \"IRMAS-TrainingData\":\n",
    "        corrected_root = irmas_root.parent\n",
    "        print(f\"üîß Adjusting path from {irmas_root} to {corrected_root}\")\n",
    "    else:\n",
    "        corrected_root = irmas_root\n",
    "\n",
    "    print(f\"üìÅ Using root path: {corrected_root}\")\n",
    "\n",
    "    # Create both original and mixed datasets using config parameters\n",
    "    original_dataset, mixed_dataset = create_multilabel_dataset(\n",
    "        irmas_root=corrected_root,\n",
    "        cfg=cfg  # All parameters now come from config\n",
    "    )\n",
    "\n",
    "    # Show final summary\n",
    "    if mixed_dataset:\n",
    "        print(f\"\\nüìà Dataset Summary:\")\n",
    "        print(f\"   Original samples: {len(original_dataset)}\")\n",
    "        print(f\"   Mixed samples: {len(mixed_dataset)}\")\n",
    "        print(f\"   Total: {len(original_dataset) + len(mixed_dataset)}\")\n",
    "else:\n",
    "    print(\"IRMAS root not found. Please run the download cell first.\")"
   ],
   "id": "4277635d9e525b8f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading IRMAS dataset to data/raw...\n",
      "Archive already exists, skipping download\n",
      "Verifying checksum ...\n",
      "Extracting ...\n",
      "Done. Data at data/raw\n",
      "IRMAS dataset found at: data/raw/IRMAS-TrainingData\n",
      "\n",
      "To preprocess the data, you can run:\n",
      "python data/preprocess.py --in_dir data/raw/IRMAS-TrainingData --out_dir data/processed\n",
      "\n",
      "Or execute this command in the next cell:\n",
      "!python data/preprocess.py --in_dir data/raw/IRMAS-TrainingData --out_dir data/processed\n"
     ]
    }
   ],
   "execution_count": 29,
   "source": [
    "\n",
    "if irmas_root:\n",
    "    print(f\"IRMAS dataset found at: {irmas_root}\")\n",
    "    PROCESSED_DIR = \"/content/IRMAS_features\" if IN_COLAB else \"data/processed\"\n",
    "\n",
    "    if 'mixed_dataset' in globals() and mixed_dataset:\n",
    "        print(f\"\\nFound {len(mixed_dataset)} mixed samples from previous cell\")\n",
    "\n",
    "        # Use config value for original data percentage\n",
    "        original_data_percentage = cfg.get('original_data_percentage', 0.1)\n",
    "        print(f\"Using {original_data_percentage*100}% of original IRMAS data (from config)\")\n",
    "\n",
    "        from data.preprocess import preprocess_mixed_data\n",
    "\n",
    "        preprocess_mixed_data(\n",
    "            irmas_root=irmas_root,\n",
    "            mixed_dataset=mixed_dataset,\n",
    "            out_dir=PROCESSED_DIR,\n",
    "            cfg=cfg,\n",
    "            original_data_percentage=original_data_percentage\n",
    "        )\n",
    "\n",
    "        print(f\"‚úÖ Preprocessing complete with mixed labels. Features saved to {PROCESSED_DIR}\")\n",
    "\n",
    "    else:\n",
    "        print(\"No mixed dataset found. Running standard preprocessing...\")\n",
    "        print(f\"To preprocess the data, you can run:\")\n",
    "        print(f\"python data/preprocess.py --in_dir {irmas_root} --out_dir {PROCESSED_DIR}\")\n",
    "\n",
    "        # Run standard preprocessing\n",
    "        preprocess_cmd = f\"!python data/preprocess.py --in_dir {irmas_root} --out_dir {PROCESSED_DIR} --config configs/default.yaml\"\n",
    "        print(f\"\\nExecuting: {preprocess_cmd}\")\n",
    "        !python data/preprocess.py --in_dir {irmas_root} --out_dir {PROCESSED_DIR} --config configs/default.yaml\n",
    "\n",
    "else:\n",
    "    print(\"Could not locate IRMAS dataset after download. Check paths and try again.\")"
   ],
   "id": "e96b51ebbb46946c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Verify the train/val/test split after preprocessing\n",
    "\n",
    "PROCESSED_DIR = \"/content/IRMAS_features\" if IN_COLAB else \"data/processed\"\n",
    "\n",
    "\n",
    "def count_samples_in_dir(dir_path):\n",
    "    \"\"\"Count samples in a directory (both original and mixed).\"\"\"\n",
    "    if not pathlib.Path(dir_path).exists():\n",
    "        return 0, 0\n",
    "\n",
    "    # Count directories (each represents one sample)\n",
    "    all_dirs = [d for d in pathlib.Path(dir_path).iterdir() if d.is_dir()]\n",
    "    mixed_dirs = [d for d in all_dirs if 'mixed_' in d.name]\n",
    "    original_dirs = [d for d in all_dirs if 'mixed_' not in d.name]\n",
    "\n",
    "    return len(original_dirs), len(mixed_dirs)\n",
    "\n",
    "\n",
    "# Check each split\n",
    "for split in ['train', 'val', 'test']:\n",
    "    split_dir = f\"{PROCESSED_DIR}/{split}\"\n",
    "    original_count, mixed_count = count_samples_in_dir(split_dir)\n",
    "    total_count = original_count + mixed_count\n",
    "\n",
    "    print(f\"üìÅ {split.upper()} split:\")\n",
    "    print(f\"   Original samples: {original_count}\")\n",
    "    print(f\"   Mixed samples: {mixed_count}\")\n",
    "    print(f\"   Total: {total_count}\")\n",
    "    print()\n",
    "\n",
    "print(\"‚úÖ Data split verification complete!\")"
   ],
   "id": "65e8d58f34a6b23d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-07T07:23:06.150747Z",
     "start_time": "2025-06-07T07:23:06.114009Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Import required modules for the model\n",
    "import torch\n",
    "from var import LABELS\n",
    "from models.panns_enhanced import MultiSTFTCNN_WithPANNs\n",
    "from data.download_pnn import download_panns_checkpoint\n",
    "\n",
    "n_classes = len(LABELS)\n",
    "\n",
    "# Download PANNs checkpoint if needed\n",
    "panns_path = download_panns_checkpoint()\n",
    "\n",
    "# Create the enhanced model with PANNs\n",
    "model = MultiSTFTCNN_WithPANNs(\n",
    "    n_classes=n_classes,  # Number of instrument classes\n",
    "    pretrained_path=panns_path,\n",
    "    freeze_backbone=False  # Use full model for inference\n",
    ")\n",
    "\n",
    "print(\"PANNs-Enhanced Architecture:\")\n",
    "print(model)\n",
    "\n",
    "# Fixed model summary for MultiSTFTCNN\n",
    "try:\n",
    "    from torchinfo import summary\n",
    "\n",
    "    # Create a wrapper class that handles the input format correctly\n",
    "    class ModelWrapper(torch.nn.Module):\n",
    "        def __init__(self, model):\n",
    "            super().__init__()\n",
    "            self.model = model\n",
    "\n",
    "        def forward(self, x1, x2, x3, x4, x5, x6, x7, x8, x9):\n",
    "            # Convert individual tensors back to list format\n",
    "            x_list = [x1, x2, x3, x4, x5, x6, x7, x8, x9]\n",
    "            return self.model(x_list)\n",
    "\n",
    "    # Wrap the model\n",
    "    wrapped_model = ModelWrapper(model)\n",
    "\n",
    "    # Create dummy input tensors with realistic dimensions\n",
    "    # Each spectrogram will have different frequency bins based on the FFT size and frequency band\n",
    "    dummy_inputs = [\n",
    "        torch.zeros(1, 1, 32, 100),   # Band 1, FFT 256\n",
    "        torch.zeros(1, 1, 64, 100),   # Band 1, FFT 512\n",
    "        torch.zeros(1, 1, 128, 100),  # Band 1, FFT 1024\n",
    "        torch.zeros(1, 1, 48, 100),   # Band 2, FFT 256\n",
    "        torch.zeros(1, 1, 96, 100),   # Band 2, FFT 512\n",
    "        torch.zeros(1, 1, 192, 100),  # Band 2, FFT 1024\n",
    "        torch.zeros(1, 1, 89, 100),   # Band 3, FFT 256\n",
    "        torch.zeros(1, 1, 178, 100),  # Band 3, FFT 512\n",
    "        torch.zeros(1, 1, 356, 100),  # Band 3, FFT 1024\n",
    "    ]\n",
    "\n",
    "    print(\"\\nModel Summary:\")\n",
    "    summary(wrapped_model, input_data=dummy_inputs, verbose=1)\n",
    "\n",
    "except ImportError:\n",
    "    print(\"\\nInstall torchinfo for detailed model summary: pip install torchinfo\")\n",
    "except Exception as e:\n",
    "    print(f\"\\nCould not generate model summary: {e}\")\n",
    "    print(\"This is normal - the model architecture is still correctly defined.\")\n",
    "\n",
    "# Alternative: Simple manual summary\n",
    "print(f\"\\nüîß Manual Model Summary:\")\n",
    "print(\"   üìä Input: 9 spectrograms (3 frequency bands √ó 3 FFT sizes)\")\n",
    "print(f\"   üß† Architecture: 9 PANNs feature extractors + fusion layer + classifier\")\n",
    "print(f\"   üì§ Output: {n_classes} instrument classes\")\n",
    "\n",
    "# Count parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"   üìà Total Parameters: {total_params:,}\")\n",
    "print(f\"   üéØ Trainable Parameters: {trainable_params:,}\")\n",
    "print(f\"   üöÄ Using PANNs pretrained weights for enhanced feature extraction\")\n",
    "\n",
    "# Test with actual dummy data to verify the model works\n",
    "print(f\"\\nüß™ Testing PANNs-enhanced model with dummy data...\")\n",
    "try:\n",
    "    # Create dummy input in the correct format (list of tensors)\n",
    "    dummy_input = [torch.zeros(2, 1, 20, 30) for _ in range(9)]  # Batch size 2\n",
    "    output = model(dummy_input)\n",
    "    print(f\"   ‚úÖ Model test successful!\")\n",
    "    print(f\"   üìä Input: 9 tensors of shape {dummy_input[0].shape}\")\n",
    "    print(f\"   üì§ Output shape: {output.shape}\")\n",
    "    print(f\"   üéØ Output range: [{output.min():.3f}, {output.max():.3f}]\")\n",
    "    print(f\"   ‚ÑπÔ∏è The PANNs model already applies sigmoid in its classifier\")\n",
    "except Exception as e:\n",
    "    print(f\"   ‚ùå Model test failed: {e}\")"
   ],
   "id": "17f023b62a55eedb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 CNN Baseline Architecture:\n",
      "MultiSTFTCNN(\n",
      "  (branches): ModuleList(\n",
      "    (0-8): 9 x STFTBranch(\n",
      "      (cnn): Sequential(\n",
      "        (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU()\n",
      "        (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "        (4): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (6): ReLU()\n",
      "        (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "        (8): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (9): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (10): ReLU()\n",
      "        (11): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "        (12): Flatten(start_dim=1, end_dim=-1)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=1152, out_features=11, bias=True)\n",
      "    (1): Sigmoid()\n",
      "  )\n",
      ")\n",
      "\n",
      "Install torchinfo for detailed model summary: pip install torchinfo\n"
     ]
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-07T07:28:46.395798Z",
     "start_time": "2025-06-07T07:28:46.390145Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Configure data paths and training settings from config\n",
    "print(\"üîß Configuring data paths and training settings...\")\n",
    "\n",
    "# Get base settings from config\n",
    "base_max_samples = cfg.get('max_samples', None)\n",
    "print(f\"üìÅ Base configuration from YAML:\")\n",
    "print(f\"   max_samples: {base_max_samples}\")\n",
    "print(f\"   max_original_samples: {cfg.get('max_original_samples', 50)}\")\n",
    "print(f\"   num_mixtures: {cfg.get('num_mixtures', 100)}\")\n",
    "print(f\"   min_instruments: {cfg.get('min_instruments', 1)}\")\n",
    "print(f\"   max_instruments: {cfg.get('max_instruments', 2)}\")\n",
    "print(f\"   original_data_percentage: {cfg.get('original_data_percentage', 0.1)}\")\n",
    "\n",
    "# Optional notebook-level override for quick experimentation\n",
    "# Uncomment and modify these lines to override config values:\n",
    "# cfg['max_samples'] = 30  # Override for faster notebook testing\n",
    "# cfg['max_original_samples'] = 25  # Override dataset creation\n",
    "# cfg['num_mixtures'] = 50  # Override number of synthetic mixtures\n",
    "\n",
    "# Check if any overrides were applied\n",
    "if base_max_samples != cfg.get('max_samples'):\n",
    "    print(f\"‚ö†Ô∏è  Notebook override: max_samples changed to {cfg.get('max_samples')}\")\n",
    "\n",
    "# Add the processed data directory to config\n",
    "PROCESSED_DIR = \"/content/IRMAS_features\" if IN_COLAB else \"data/processed\"\n",
    "cfg['data_dir'] = PROCESSED_DIR\n",
    "cfg['train_dir'] = f\"{PROCESSED_DIR}/train\"\n",
    "cfg['val_dir'] = f\"{PROCESSED_DIR}/val\"\n",
    "cfg['test_dir'] = f\"{PROCESSED_DIR}/test\"\n",
    "\n",
    "print(f\"\\nüìÇ Data directories:\")\n",
    "print(f\"   Processed data: {PROCESSED_DIR}\")\n",
    "print(f\"   Training: {cfg['train_dir']}\")\n",
    "print(f\"   Validation: {cfg['val_dir']}\")\n",
    "print(f\"   Test: {cfg['test_dir']}\")\n",
    "\n",
    "# Verify that data directories exist and contain samples\n",
    "import pathlib\n",
    "\n",
    "print(f\"\\nüîç Verifying data directories:\")\n",
    "for split in ['train', 'val', 'test']:\n",
    "    split_dir = f\"{PROCESSED_DIR}/{split}\"\n",
    "    if pathlib.Path(split_dir).exists():\n",
    "        sample_count = len([d for d in pathlib.Path(split_dir).iterdir() if d.is_dir()])\n",
    "        print(f\"   {split}: {sample_count} samples\")\n",
    "        if sample_count == 0:\n",
    "            print(f\"   ‚ö†Ô∏è  Warning: {split} directory is empty!\")\n",
    "    else:\n",
    "        print(f\"   ‚ùå {split} directory doesn't exist!\")\n",
    "\n",
    "# Display final configuration summary\n",
    "print(f\"\\n‚úÖ Final training configuration:\")\n",
    "print(f\"   Training samples limit: {cfg.get('max_samples', 'unlimited')}\")\n",
    "print(f\"   Batch size: {cfg.get('batch_size')}\")\n",
    "print(f\"   Validation limit: {cfg.get('limit_val_batches', 1.0)} ({'percentage' if cfg.get('limit_val_batches', 1.0) <= 1 else 'batches'})\")\n",
    "print(f\"   Learning rate: {cfg.get('learning_rate')}\")\n",
    "print(f\"   Epochs: {cfg.get('num_epochs')}\")"
   ],
   "id": "11f0f267a4c9c98c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with limited samples: 1\n"
     ]
    }
   ],
   "execution_count": 40
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-06-07T07:28:47.933285Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Training with better error handling and debugging\n",
    "print(\"üöÄ Starting training...\")\n",
    "print(f\"üìÅ Configuration:\")\n",
    "print(f\"   max_samples: {cfg.get('max_samples', 'all')}\")\n",
    "print(f\"   train_dir: {cfg.get('train_dir', 'not set')}\")\n",
    "print(f\"   val_dir: {cfg.get('val_dir', 'not set')}\")\n",
    "print(f\"   batch_size: {cfg.get('batch_size', 'not set')}\")\n",
    "print(f\"   limit_val_batches: {cfg.get('limit_val_batches', 1.0)} ({'percentage' if cfg.get('limit_val_batches', 1.0) <= 1 else 'batches'})\")\n",
    "print(f\"   num_sanity_val_steps: {cfg.get('num_sanity_val_steps', 'default')}\")\n",
    "\n",
    "# Optional: Override validation settings for even faster development\n",
    "# cfg['limit_val_batches'] = 0.05  # Use only 5% for even faster validation\n",
    "# cfg['num_sanity_val_steps'] = 1   # Minimal sanity checks\n",
    "\n",
    "try:\n",
    "    # Try direct import first\n",
    "    from training.panns_train import main as train_main\n",
    "\n",
    "    print(\"‚úÖ Direct import successful, PANNs-enhanced training...\")\n",
    "\n",
    "    # Debug: Check if training directory has data\n",
    "    train_dir = cfg.get('train_dir')\n",
    "    if train_dir and pathlib.Path(train_dir).exists():\n",
    "        sample_dirs = [d for d in pathlib.Path(train_dir).iterdir() if d.is_dir()]\n",
    "        print(f\"üîç Found {len(sample_dirs)} training samples\")\n",
    "        if len(sample_dirs) == 0:\n",
    "            print(\"‚ùå Training directory is empty! Cannot proceed.\")\n",
    "            print(\"üí° Make sure you've run the preprocessing step successfully.\")\n",
    "        else:\n",
    "            # Show first few samples\n",
    "            print(f\"üìÇ Sample directories: {[d.name for d in sample_dirs[:3]]}\")\n",
    "            train_main(cfg)\n",
    "            print(\"üéâ Training completed successfully!\")\n",
    "    else:\n",
    "        print(f\"‚ùå Training directory not found: {train_dir}\")\n",
    "        print(\"üí° Make sure you've run the preprocessing step successfully.\")\n",
    "\n",
    "except ImportError as import_error:\n",
    "    print(f\"‚ùå Import error: {import_error}\")\n",
    "    print(\"üí° This likely means pytorch-lightning is not installed.\")\n",
    "\n",
    "    if IN_COLAB:\n",
    "        print(\"üì¶ Installing pytorch-lightning...\")\n",
    "        !pip install pytorch-lightning>=2.0.0 --quiet\n",
    "        print(\"‚úÖ Dependency installed, retrying...\")\n",
    "\n",
    "        # Retry after installation\n",
    "        try:\n",
    "            from training.train import main as train_main\n",
    "\n",
    "            train_main(cfg)\n",
    "            print(\"üéâ Training completed successfully!\")\n",
    "        except Exception as retry_error:\n",
    "            print(f\"‚ùå Still failing after dependency installation: {retry_error}\")\n",
    "            import traceback\n",
    "\n",
    "            traceback.print_exc()\n",
    "    else:\n",
    "        print(\"Please install: pip install pytorch-lightning>=2.0.0\")\n",
    "\n",
    "except Exception as general_error:\n",
    "    print(f\"‚ùå Training error: {general_error}\")\n",
    "    print(\"üìã Error details:\")\n",
    "    import traceback\n",
    "\n",
    "    traceback.print_exc()\n",
    "\n",
    "    # Additional debugging\n",
    "    if \"num_samples=0\" in str(general_error):\n",
    "        print(\"\\nüîç Debugging empty dataset issue:\")\n",
    "        train_dir = cfg.get('train_dir')\n",
    "        if train_dir:\n",
    "            print(f\"   Checking {train_dir}...\")\n",
    "            if pathlib.Path(train_dir).exists():\n",
    "                sample_dirs = list(pathlib.Path(train_dir).iterdir())\n",
    "                print(f\"   Found {len(sample_dirs)} items in training directory\")\n",
    "                for item in sample_dirs[:5]:\n",
    "                    print(f\"     - {item.name} ({'dir' if item.is_dir() else 'file'})\")\n",
    "            else:\n",
    "                print(f\"   Directory {train_dir} does not exist!\")\n",
    "        else:\n",
    "            print(\"   train_dir not set in config!\")"
   ],
   "id": "9d09f471df9d60b6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error with direct import: expected str, bytes or os.PathLike object, not dict\n",
      "Falling back to shell command\n",
      "GPU available: False, used: False\r\n",
      "TPU available: False, using: 0 TPU cores\r\n",
      "IPU available: False, using: 0 IPUs\r\n",
      "HPU available: False, using: 0 HPUs\r\n",
      "/home/odahan/Technion/Semester_8/Deep_Learning/Project/.venv/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/logger_connector/logger_connector.py:67: UserWarning: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `pytorch_lightning` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\r\n",
      "  warning_cache.warn(\r\n",
      "\r\n",
      "  | Name    | Type             | Params\r\n",
      "---------------------------------------------\r\n",
      "0 | model   | MultiSTFTCNN     | 850 K \r\n",
      "1 | metrics | MetricCollection | 0     \r\n",
      "---------------------------------------------\r\n",
      "850 K     Trainable params\r\n",
      "0         Non-trainable params\r\n",
      "850 K     Total params\r\n",
      "3.403     Total estimated model params size (MB)\r\n",
      "Sanity Checking DataLoader 0:   0%|                       | 0/2 [00:00<?, ?it/s]/home/odahan/Technion/Semester_8/Deep_Learning/Project/.venv/lib/python3.9/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: Average precision score for one or more classes was `nan`. Ignoring these classes in macro-average\r\n",
      "  warnings.warn(*args, **kwargs)  # noqa: B028\r\n",
      "/home/odahan/Technion/Semester_8/Deep_Learning/Project/.venv/lib/python3.9/site-packages/pytorch_lightning/loops/fit_loop.py:280: PossibleUserWarning: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\r\n",
      "  rank_zero_warn(\r\n",
      "Epoch 0: 100%|‚ñà| 1/1 [00:01<00:00,  1.01s/it, v_num=2, train/loss=0.738, train/m\r\n",
      "Validation: 0it [00:00, ?it/s]\u001B[A\r\n",
      "Validation:   0%|                                       | 0/160 [00:00<?, ?it/s]\u001B[A\r\n",
      "Validation DataLoader 0:   0%|                          | 0/160 [00:00<?, ?it/s]\u001B[A\r\n",
      "Validation DataLoader 0:   1%|                  | 1/160 [00:02<06:30,  2.46s/it]\u001B[A\r\n",
      "Validation DataLoader 0:   1%|‚ñè                 | 2/160 [00:04<06:01,  2.29s/it]\u001B[A\r\n",
      "Validation DataLoader 0:   2%|‚ñé                 | 3/160 [00:06<05:44,  2.20s/it]\u001B[A\r\n",
      "Validation DataLoader 0:   2%|‚ñç                 | 4/160 [00:08<05:34,  2.14s/it]\u001B[A\r\n",
      "Validation DataLoader 0:   3%|‚ñå                 | 5/160 [00:11<05:55,  2.29s/it]\u001B[A\r\n",
      "Validation DataLoader 0:   4%|‚ñã                 | 6/160 [00:13<05:53,  2.30s/it]\u001B[A\r\n",
      "Validation DataLoader 0:   4%|‚ñä                 | 7/160 [00:15<05:48,  2.28s/it]\u001B[A\r\n",
      "Validation DataLoader 0:   5%|‚ñâ                 | 8/160 [00:17<05:41,  2.25s/it]\u001B[A\r\n",
      "Validation DataLoader 0:   6%|‚ñà                 | 9/160 [00:20<05:35,  2.22s/it]\u001B[A\r\n",
      "Validation DataLoader 0:   6%|‚ñà                | 10/160 [00:22<05:31,  2.21s/it]\u001B[A\r\n",
      "Validation DataLoader 0:   7%|‚ñà‚ñè               | 11/160 [00:24<05:35,  2.25s/it]\u001B[A\r\n",
      "Validation DataLoader 0:   8%|‚ñà‚ñé               | 12/160 [00:27<05:39,  2.29s/it]\u001B[A\r\n",
      "Validation DataLoader 0:   8%|‚ñà‚ñç               | 13/160 [00:29<05:38,  2.30s/it]\u001B[A\r\n",
      "Validation DataLoader 0:   9%|‚ñà‚ñç               | 14/160 [00:31<05:31,  2.27s/it]\u001B[A\r\n",
      "Validation DataLoader 0:   9%|‚ñà‚ñå               | 15/160 [00:33<05:26,  2.25s/it]\u001B[A\r\n",
      "Validation DataLoader 0:  10%|‚ñà‚ñã               | 16/160 [00:35<05:21,  2.23s/it]\u001B[A\r\n",
      "Validation DataLoader 0:  11%|‚ñà‚ñä               | 17/160 [00:37<05:17,  2.22s/it]\u001B[A\r\n",
      "Validation DataLoader 0:  11%|‚ñà‚ñâ               | 18/160 [00:39<05:13,  2.21s/it]\u001B[A\r\n",
      "Validation DataLoader 0:  12%|‚ñà‚ñà               | 19/160 [00:41<05:09,  2.20s/it]\u001B[A\r\n",
      "Validation DataLoader 0:  12%|‚ñà‚ñà‚ñè              | 20/160 [00:43<05:05,  2.18s/it]\u001B[A\r\n",
      "Validation DataLoader 0:  13%|‚ñà‚ñà‚ñè              | 21/160 [00:45<05:01,  2.17s/it]\u001B[A\r\n",
      "Validation DataLoader 0:  14%|‚ñà‚ñà‚ñé              | 22/160 [00:47<04:58,  2.16s/it]\u001B[A\r\n",
      "Validation DataLoader 0:  14%|‚ñà‚ñà‚ñç              | 23/160 [00:49<04:55,  2.16s/it]\u001B[A\r\n",
      "Validation DataLoader 0:  15%|‚ñà‚ñà‚ñå              | 24/160 [00:52<04:55,  2.17s/it]\u001B[A\r\n",
      "Validation DataLoader 0:  16%|‚ñà‚ñà‚ñã              | 25/160 [00:54<04:55,  2.19s/it]\u001B[A\r\n",
      "Validation DataLoader 0:  16%|‚ñà‚ñà‚ñä              | 26/160 [00:56<04:53,  2.19s/it]\u001B[A\r\n",
      "Validation DataLoader 0:  17%|‚ñà‚ñà‚ñä              | 27/160 [00:58<04:50,  2.18s/it]\u001B[A\r\n",
      "Validation DataLoader 0:  18%|‚ñà‚ñà‚ñâ              | 28/160 [01:00<04:46,  2.17s/it]\u001B[A\r\n",
      "Validation DataLoader 0:  18%|‚ñà‚ñà‚ñà              | 29/160 [01:02<04:43,  2.17s/it]\u001B[A\r\n",
      "Validation DataLoader 0:  19%|‚ñà‚ñà‚ñà‚ñè             | 30/160 [01:04<04:40,  2.16s/it]\u001B[A\r\n",
      "Validation DataLoader 0:  19%|‚ñà‚ñà‚ñà‚ñé             | 31/160 [01:06<04:37,  2.15s/it]\u001B[A\r\n",
      "Validation DataLoader 0:  20%|‚ñà‚ñà‚ñà‚ñç             | 32/160 [01:08<04:34,  2.15s/it]\u001B[A\r\n",
      "Validation DataLoader 0:  21%|‚ñà‚ñà‚ñà‚ñå             | 33/160 [01:10<04:32,  2.14s/it]\u001B[A\r\n",
      "Validation DataLoader 0:  21%|‚ñà‚ñà‚ñà‚ñå             | 34/160 [01:12<04:29,  2.14s/it]\u001B[A\r\n",
      "Validation DataLoader 0:  22%|‚ñà‚ñà‚ñà‚ñã             | 35/160 [01:14<04:26,  2.13s/it]\u001B[A\r\n",
      "Validation DataLoader 0:  22%|‚ñà‚ñà‚ñà‚ñä             | 36/160 [01:16<04:23,  2.13s/it]\u001B[A\r\n",
      "Validation DataLoader 0:  23%|‚ñà‚ñà‚ñà‚ñâ             | 37/160 [01:18<04:21,  2.12s/it]\u001B[A\r\n",
      "Validation DataLoader 0:  24%|‚ñà‚ñà‚ñà‚ñà             | 38/160 [01:20<04:18,  2.12s/it]\u001B[A\r\n",
      "Validation DataLoader 0:  24%|‚ñà‚ñà‚ñà‚ñà‚ñè            | 39/160 [01:22<04:17,  2.12s/it]\u001B[A\r\n",
      "Validation DataLoader 0:  25%|‚ñà‚ñà‚ñà‚ñà‚ñé            | 40/160 [01:26<04:18,  2.16s/it]\u001B[A\r\n",
      "Validation DataLoader 0:  26%|‚ñà‚ñà‚ñà‚ñà‚ñé            | 41/160 [01:29<04:20,  2.19s/it]\u001B[A\r\n",
      "Validation DataLoader 0:  26%|‚ñà‚ñà‚ñà‚ñà‚ñç            | 42/160 [01:32<04:20,  2.20s/it]\u001B[A\r\n",
      "Validation DataLoader 0:  27%|‚ñà‚ñà‚ñà‚ñà‚ñå            | 43/160 [01:34<04:17,  2.20s/it]\u001B[A\r\n",
      "Validation DataLoader 0:  28%|‚ñà‚ñà‚ñà‚ñà‚ñã            | 44/160 [01:36<04:14,  2.19s/it]\u001B[A\r\n",
      "Validation DataLoader 0:  28%|‚ñà‚ñà‚ñà‚ñà‚ñä            | 45/160 [01:38<04:11,  2.19s/it]\u001B[A\r\n",
      "Validation DataLoader 0:  29%|‚ñà‚ñà‚ñà‚ñà‚ñâ            | 46/160 [01:40<04:09,  2.19s/it]\u001B[A\r\n",
      "Validation DataLoader 0:  29%|‚ñà‚ñà‚ñà‚ñà‚ñâ            | 47/160 [01:42<04:06,  2.18s/it]\u001B[A\r\n",
      "Validation DataLoader 0:  30%|‚ñà‚ñà‚ñà‚ñà‚ñà            | 48/160 [01:44<04:03,  2.18s/it]\u001B[A\r\n",
      "Validation DataLoader 0:  31%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè           | 49/160 [01:46<04:01,  2.18s/it]\u001B[A\r\n",
      "Validation DataLoader 0:  31%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé           | 50/160 [01:48<03:59,  2.17s/it]\u001B[A\r\n",
      "Validation DataLoader 0:  32%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç           | 51/160 [01:50<03:56,  2.17s/it]\u001B[A\r\n",
      "Validation DataLoader 0:  32%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå           | 52/160 [01:52<03:54,  2.17s/it]\u001B[A\r\n",
      "Validation DataLoader 0:  33%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã           | 53/160 [01:55<03:52,  2.17s/it]\u001B[A\r\n",
      "Validation DataLoader 0:  34%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã           | 54/160 [01:57<03:49,  2.17s/it]\u001B[A\r\n",
      "Validation DataLoader 0:  34%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä           | 55/160 [01:59<03:47,  2.17s/it]\u001B[A\r\n",
      "Validation DataLoader 0:  35%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ           | 56/160 [02:01<03:45,  2.16s/it]\u001B[A\r\n",
      "Validation DataLoader 0:  36%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà           | 57/160 [02:03<03:42,  2.16s/it]\u001B[A\r\n",
      "Validation DataLoader 0:  36%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè          | 58/160 [02:05<03:40,  2.16s/it]\u001B[A\r\n",
      "Validation DataLoader 0:  37%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé          | 59/160 [02:07<03:37,  2.16s/it]\u001B[A\r\n",
      "Validation DataLoader 0:  38%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç          | 60/160 [02:09<03:35,  2.15s/it]\u001B[A\r\n",
      "Validation DataLoader 0:  38%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç          | 61/160 [02:11<03:33,  2.16s/it]\u001B[A\r\n",
      "Validation DataLoader 0:  39%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå          | 62/160 [02:13<03:30,  2.15s/it]\u001B[A\r\n",
      "Validation DataLoader 0:  39%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã          | 63/160 [02:15<03:28,  2.15s/it]\u001B[A\r\n",
      "Validation DataLoader 0:  40%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä          | 64/160 [02:17<03:26,  2.15s/it]\u001B[A\r\n",
      "Validation DataLoader 0:  41%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ          | 65/160 [02:19<03:23,  2.15s/it]\u001B[A\r\n",
      "Validation DataLoader 0:  41%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà          | 66/160 [02:21<03:21,  2.14s/it]\u001B[A\r\n",
      "Validation DataLoader 0:  42%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà          | 67/160 [02:23<03:19,  2.14s/it]\u001B[A\r\n",
      "Validation DataLoader 0:  42%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè         | 68/160 [02:26<03:17,  2.15s/it]\u001B[A\r\n",
      "Validation DataLoader 0:  43%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé         | 69/160 [02:28<03:16,  2.15s/it]\u001B[A\r\n",
      "Validation DataLoader 0:  44%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç         | 70/160 [02:31<03:14,  2.16s/it]\u001B[A\r\n",
      "Validation DataLoader 0:  44%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå         | 71/160 [02:33<03:11,  2.16s/it]\u001B[A\r\n",
      "Validation DataLoader 0:  45%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã         | 72/160 [02:35<03:10,  2.16s/it]\u001B[A\r\n",
      "Validation DataLoader 0:  46%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä         | 73/160 [02:37<03:08,  2.16s/it]\u001B[A\r\n",
      "Validation DataLoader 0:  46%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä         | 74/160 [02:39<03:05,  2.16s/it]\u001B[A\r\n",
      "Validation DataLoader 0:  47%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ         | 75/160 [02:41<03:03,  2.16s/it]\u001B[A\r\n",
      "Validation DataLoader 0:  48%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà         | 76/160 [02:44<03:01,  2.16s/it]\u001B[A\r\n",
      "Validation DataLoader 0:  48%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè        | 77/160 [02:46<02:59,  2.16s/it]\u001B[A\r\n",
      "Validation DataLoader 0:  49%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé        | 78/160 [02:48<02:56,  2.16s/it]\u001B[A"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Inference and visualization using the test set\n",
    "\n",
    "import glob\n",
    "import re\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "import torch\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n"
   ],
   "id": "3c6d514e82b02103"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Setup inference with adaptive thresholds\n",
    "print(\"üöÄ Running inference with adaptive thresholds\")\n",
    "\n",
    "# Step 1: Find the best checkpoint\n",
    "def find_best_checkpoint(lightning_logs_dir=\"lightning_logs\"):\n",
    "    \"\"\"Find the best checkpoint based on validation mAP\"\"\"\n",
    "    # Find all checkpoints\n",
    "    checkpoint_pattern = f\"{lightning_logs_dir}/*/checkpoints/*.ckpt\"\n",
    "    checkpoints = glob.glob(checkpoint_pattern)\n",
    "\n",
    "    if not checkpoints:\n",
    "        print(f\"‚ùå No checkpoints found in {lightning_logs_dir}\")\n",
    "        return None\n",
    "\n",
    "    print(f\"üîç Found {len(checkpoints)} checkpoint(s)\")\n",
    "\n",
    "    best_checkpoint = None\n",
    "    best_map = -1\n",
    "    best_epoch = -1\n",
    "\n",
    "    for ckpt_path in checkpoints:\n",
    "        ckpt_name = Path(ckpt_path).name\n",
    "\n",
    "        # Parse metrics from filename\n",
    "        epoch_match = re.search(r'epoch=(\\d+)', ckpt_name)\n",
    "        map_match = re.search(r'val_mAP=([0-9.]+)(?=\\.ckpt)', ckpt_name)\n",
    "\n",
    "        if epoch_match and map_match:\n",
    "            epoch = int(epoch_match.group(1))\n",
    "            val_map = float(map_match.group(1))\n",
    "\n",
    "            if val_map > best_map or (val_map == best_map and epoch > best_epoch):\n",
    "                best_checkpoint = ckpt_path\n",
    "                best_map = val_map\n",
    "                best_epoch = epoch\n",
    "\n",
    "    if best_checkpoint:\n",
    "        print(f\"‚úÖ Selected best checkpoint: {best_checkpoint}\")\n",
    "        print(f\"   Epoch: {best_epoch}, val_mAP: {best_map:.4f}\")\n",
    "        return best_checkpoint\n",
    "    else:\n",
    "        # Fallback to first available checkpoint\n",
    "        print(f\"‚ö†Ô∏è Selecting first available checkpoint: {checkpoints[0]}\")\n",
    "        return checkpoints[0]\n",
    "\n",
    "# Step 2: Load thresholds and model\n",
    "def load_adaptive_thresholds(threshold_file=\"configs/optimal_thresholds_f1.yaml\"):\n",
    "    \"\"\"Load instrument-specific thresholds from file\"\"\"\n",
    "    try:\n",
    "        with open(threshold_file, 'r') as f:\n",
    "            threshold_data = yaml.safe_load(f)\n",
    "            thresholds = threshold_data.get('thresholds', {})\n",
    "            print(f\"‚úÖ Loaded {len(thresholds)} thresholds from {threshold_file}\")\n",
    "            return thresholds\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Could not load thresholds: {e}\")\n",
    "        return None\n",
    "\n",
    "# Find best checkpoint\n",
    "ckpt_path = find_best_checkpoint()\n",
    "\n",
    "# Load thresholds\n",
    "f1_thresholds = load_adaptive_thresholds(\"configs/optimal_thresholds_f1.yaml\")\n",
    "balanced_thresholds = load_adaptive_thresholds(\"configs/optimal_thresholds_balanced.yaml\")\n",
    "\n",
    "# Setup model and config\n",
    "if ckpt_path:\n",
    "    # Load configuration\n",
    "    config_path = yaml_path\n",
    "    with open(config_path, 'r') as f:\n",
    "        cfg = yaml.safe_load(f)\n",
    "\n",
    "    # Import the model loading function\n",
    "    from inference.predict import load_model_from_checkpoint\n",
    "    from var import LABELS\n",
    "\n",
    "    # Load model\n",
    "    model = load_model_from_checkpoint(ckpt_path, len(LABELS))\n",
    "    model.eval()\n",
    "\n",
    "    print(\"‚úÖ Model loaded successfully!\")\n",
    "\n",
    "    # Find test files\n",
    "    if 'irmas_root' in globals() and irmas_root:\n",
    "        test_files = list(Path(irmas_root).rglob(\"*.wav\"))[:5]  # Limit to 5 files\n",
    "\n",
    "        if test_files:\n",
    "            print(f\"üìä Running inference on {len(test_files)} test files\")\n",
    "\n",
    "            # Import prediction function\n",
    "            from inference.predict import predict_with_ground_truth\n",
    "\n",
    "            for i, wav_file in enumerate(test_files):\n",
    "                print(f\"\\nüéµ File {i+1}/{len(test_files)}: {wav_file.name}\")\n",
    "\n",
    "                # Run with different threshold strategies\n",
    "                strategies = {\n",
    "                    \"Fixed (0.5)\": None,\n",
    "                    \"F1 Optimized\": f1_thresholds,\n",
    "                    \"Balanced\": balanced_thresholds\n",
    "                }\n",
    "\n",
    "                results = {}\n",
    "                for name, thresholds in strategies.items():\n",
    "                    if name != \"Fixed (0.5)\" and thresholds is None:\n",
    "                        continue\n",
    "\n",
    "                    # Set default threshold based on strategy\n",
    "                    default_threshold = 0.5 if name == \"Fixed (0.5)\" else 0.5\n",
    "\n",
    "                    # Run prediction with appropriate thresholds\n",
    "                    result = predict_with_ground_truth(\n",
    "                        model, str(wav_file), cfg,\n",
    "                        threshold=default_threshold,\n",
    "                        thresholds=thresholds\n",
    "                    )\n",
    "\n",
    "                    results[name] = result\n",
    "\n",
    "                # Display ground truth if available\n",
    "                if \"ground_truth\" in results[\"Fixed (0.5)\"]:\n",
    "                    gt = results[\"Fixed (0.5)\"][\"ground_truth\"]\n",
    "                    print(f\"üéØ Ground truth: {gt}\")\n",
    "\n",
    "                # Compare results\n",
    "                print(\"\\nüìä Detected instruments by threshold strategy:\")\n",
    "                for name, result in results.items():\n",
    "                    active = result[\"active_instruments\"]\n",
    "                    active_str = \", \".join(active) if active else \"None\"\n",
    "                    acc = result.get(\"accuracy\", None)\n",
    "                    acc_str = f\" (Accuracy: {acc:.2f})\" if acc is not None else \"\"\n",
    "                    print(f\"   {name}: {active_str}{acc_str}\")\n",
    "\n",
    "                # Show top 5 predictions with scores\n",
    "                print(\"\\nüìä Top 5 predictions (with Fixed threshold):\")\n",
    "                top_preds = sorted(results[\"Fixed (0.5)\"][\"predictions\"].items(), key=lambda x: x[1], reverse=True)[:5]\n",
    "                for label, score in top_preds:\n",
    "                    threshold = f1_thresholds.get(label, 0.5) if f1_thresholds else 0.5\n",
    "                    active = \"‚úÖ\" if score >= threshold else \"‚ùå\"\n",
    "                    print(f\"   {active} {label:<15} {score:.4f} (threshold: {threshold:.2f})\")\n",
    "\n",
    "                # Visualize first file only\n",
    "                if i == 0:\n",
    "                    try:\n",
    "                        # Load audio for visualization\n",
    "                        y, sr = librosa.load(str(wav_file), sr=cfg['sample_rate'])\n",
    "\n",
    "                        # Plot waveform\n",
    "                        plt.figure(figsize=(12, 4))\n",
    "                        plt.plot(np.linspace(0, len(y)/sr, len(y)), y)\n",
    "                        plt.title(f\"Waveform: {wav_file.name}\")\n",
    "                        plt.xlabel(\"Time (s)\")\n",
    "                        plt.ylabel(\"Amplitude\")\n",
    "                        plt.show()\n",
    "\n",
    "                        # Plot spectrogram\n",
    "                        D = librosa.amplitude_to_db(np.abs(librosa.stft(y)), ref=np.max)\n",
    "                        plt.figure(figsize=(12, 6))\n",
    "                        librosa.display.specshow(D, sr=sr, x_axis='time', y_axis='log')\n",
    "                        plt.colorbar(format='%+2.0f dB')\n",
    "                        plt.title(f\"Spectrogram: {wav_file.name}\")\n",
    "                        plt.show()\n",
    "                    except Exception as e:\n",
    "                        print(f\"‚ö†Ô∏è Visualization error: {e}\")\n",
    "        else:\n",
    "            print(\"‚ùå No test files found\")\n",
    "    else:\n",
    "        print(\"‚ùå IRMAS root not found\")\n",
    "else:\n",
    "    print(\"‚ùå No checkpoint found. Please run training first.\")\n"
   ],
   "id": "aa9af416100cf409"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Threshold Optimization\n",
    "\n",
    "Optimize classification thresholds to improve instrument detection accuracy.\n"
   ],
   "id": "e04b4f3977a910c2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Run threshold optimization if needed\n",
    "print(\"üéØ Threshold Optimization\")\n",
    "\n",
    "# Check if we already have a best checkpoint\n",
    "if not 'ckpt_path' in globals() or ckpt_path is None:\n",
    "    print(\"‚ùå No checkpoint found! Run the training cell first.\")\n",
    "    ckpt_path = None\n",
    "else:\n",
    "    print(f\"‚úÖ Using checkpoint: {ckpt_path}\")\n",
    "\n",
    "    # Check if thresholds already exist\n",
    "    f1_thresholds_exist = os.path.exists('configs/optimal_thresholds_f1.yaml')\n",
    "    balanced_thresholds_exist = os.path.exists('configs/optimal_thresholds_balanced.yaml')\n",
    "\n",
    "    if f1_thresholds_exist and balanced_thresholds_exist:\n",
    "        print(\"‚úÖ Threshold files already exist. Set regenerate=True to recreate them.\")\n",
    "        regenerate = False  # Change to True to force regeneration\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è Threshold files not found. Will generate them.\")\n",
    "        regenerate = True\n",
    "\n",
    "    if regenerate:\n",
    "        print(\"\\nüß™ Running threshold optimization...\")\n",
    "\n",
    "        try:\n",
    "            # Import the threshold optimization module\n",
    "            from visualization.threshold_optimization import find_optimal_thresholds, save_thresholds\n",
    "            from data.dataset import create_dataloaders\n",
    "            from inference.predict import load_model_from_checkpoint\n",
    "            from var import LABELS\n",
    "\n",
    "            # Load model\n",
    "            model = load_model_from_checkpoint(ckpt_path, len(LABELS), cfg)\n",
    "\n",
    "            # Create validation dataloader\n",
    "            val_dir = cfg.get('val_dir', 'data/processed/val')\n",
    "            _, val_loader = create_dataloaders(\n",
    "                train_dir=\"data/processed/train\",  # Not used\n",
    "                val_dir=val_dir,\n",
    "                batch_size=cfg.get('batch_size', 32),\n",
    "                num_workers=cfg.get('num_workers', 4),\n",
    "                use_multi_stft=True\n",
    "            )\n",
    "\n",
    "            # Generate F1-optimized thresholds\n",
    "            print(\"\\nüìä Optimizing thresholds for F1 score...\")\n",
    "            f1_thresholds = find_optimal_thresholds(model, val_loader, metric='f1')\n",
    "            save_thresholds(f1_thresholds, 'configs/optimal_thresholds_f1.yaml', 'f1')\n",
    "\n",
    "            # Generate balanced accuracy thresholds\n",
    "            print(\"\\nüìä Optimizing thresholds for balanced accuracy...\")\n",
    "            balanced_thresholds = find_optimal_thresholds(model, val_loader, metric='balanced')\n",
    "            save_thresholds(balanced_thresholds, 'configs/optimal_thresholds_balanced.yaml', 'balanced')\n",
    "\n",
    "            print(\"\\n‚úÖ Threshold optimization complete!\")\n",
    "            print(\"   You can now use these thresholds for improved instrument detection.\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error during threshold optimization: {e}\")\n",
    "            print(\"   You can still run threshold optimization manually:\")\n",
    "            print(\"   python visualization/optimize_thresholds.py CHECKPOINT_PATH\")\n",
    "    else:\n",
    "        print(\"\\n‚ÑπÔ∏è To manually run threshold optimization:\")\n",
    "        print(\"   python visualization/optimize_thresholds.py CHECKPOINT_PATH\")\n",
    "        print(\"   python visualization/optimize_thresholds.py --metric balanced CHECKPOINT_PATH\")\n"
   ],
   "id": "da78f158c7ccbfd7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Adaptive Threshold Evaluation (New Feature)\n",
   "id": "9572b21f92bceb4a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "print(\"üîç Loading model for instrument recognition\")\n",
    "\n",
    "# Load adaptive thresholds for improved accuracy\n",
    "f1_thresholds = None\n",
    "try:\n",
    "    # Get thresholds path based on environment\n",
    "    f1_thresholds_path = 'configs/optimal_thresholds_f1.yaml' if not IN_COLAB else '/content/DL_Project/configs/optimal_thresholds_f1.yaml'\n",
    "\n",
    "    if os.path.exists(f1_thresholds_path):\n",
    "        print(f\"‚úÖ Found F1-optimized thresholds at {f1_thresholds_path}\")\n",
    "        with open(f1_thresholds_path, 'r') as f:\n",
    "            threshold_data = yaml.safe_load(f)\n",
    "            f1_thresholds = threshold_data.get('thresholds', {})\n",
    "            print(f\"   Loaded {len(f1_thresholds)} instrument-specific thresholds\")\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è F1 thresholds file not found\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è Error loading thresholds: {e}\")\n",
    "\n",
    "\n",
    "# Find the best checkpoint\n",
    "def find_best_checkpoint(lightning_logs_dir=None):\n",
    "    \"\"\"Find the best checkpoint with highest validation mAP\"\"\"\n",
    "    # Auto-detect lightning_logs directory\n",
    "    if lightning_logs_dir is None:\n",
    "        possible_dirs = [\n",
    "            \"/content/DL_Project/lightning_logs\",\n",
    "            \"/content/DL_Project/DL_Project/lightning_logs\",\n",
    "            \"lightning_logs\",\n",
    "            \"./lightning_logs\"\n",
    "        ]\n",
    "\n",
    "        for dir_path in possible_dirs:\n",
    "            if Path(dir_path).exists():\n",
    "                lightning_logs_dir = dir_path\n",
    "                print(f\"üîç Found lightning_logs at: {lightning_logs_dir}\")\n",
    "                break\n",
    "\n",
    "        if lightning_logs_dir is None:\n",
    "            print(\"‚ùå Could not find lightning_logs directory\")\n",
    "            return None\n",
    "\n",
    "    # Get all checkpoint files\n",
    "    checkpoint_pattern = f\"{lightning_logs_dir}/*/checkpoints/*.ckpt\"\n",
    "    checkpoints = glob.glob(checkpoint_pattern)\n",
    "\n",
    "    if not checkpoints:\n",
    "        print(f\"‚ùå No checkpoints found\")\n",
    "        return None\n",
    "\n",
    "    print(f\"üîç Found {len(checkpoints)} checkpoint(s)\")\n",
    "\n",
    "    # Find best checkpoint based on validation mAP\n",
    "    best_checkpoint = None\n",
    "    best_map = -1\n",
    "    best_epoch = -1\n",
    "\n",
    "    for ckpt_path in checkpoints:\n",
    "        ckpt_name = Path(ckpt_path).name\n",
    "        epoch_match = re.search(r'epoch=(\\d+)', ckpt_name)\n",
    "        map_match = re.search(r'val_mAP=([0-9.]+)(?=\\.ckpt)', ckpt_name)\n",
    "\n",
    "        if epoch_match and map_match:\n",
    "            epoch = int(epoch_match.group(1))\n",
    "            try:\n",
    "                val_map = float(map_match.group(1))\n",
    "                # Select highest mAP, or highest epoch as tiebreaker\n",
    "                if val_map > best_map or (val_map == best_map and epoch > best_epoch):\n",
    "                    best_checkpoint = ckpt_path\n",
    "                    best_map = val_map\n",
    "                    best_epoch = epoch\n",
    "            except ValueError:\n",
    "                pass\n",
    "\n",
    "    if best_checkpoint:\n",
    "        print(f\"\\nüèÜ Selected best checkpoint: {Path(best_checkpoint).name}\")\n",
    "        print(f\"   üìä Epoch: {best_epoch}, val_mAP: {best_map:.4f}\")\n",
    "        return best_checkpoint\n",
    "    elif checkpoints:  # Fallback to first checkpoint\n",
    "        print(f\"üí° Using first available checkpoint as fallback\")\n",
    "        return checkpoints[0]\n",
    "    return None\n",
    "\n",
    "\n",
    "# Load checkpoint and run inference\n",
    "ckpt_path = find_best_checkpoint()\n",
    "config_path = yaml_path\n",
    "\n",
    "if not ckpt_path:\n",
    "    print(\"‚ùå No checkpoint found! Make sure training completed successfully.\")\n",
    "else:\n",
    "    print(f\"‚úÖ Will use checkpoint: {ckpt_path}\")\n",
    "\n",
    "    # Prepare test data\n",
    "    PROCESSED_DIR = \"/content/IRMAS_features\" if IN_COLAB else \"data/processed\"\n",
    "    test_data_dir = f\"{PROCESSED_DIR}/test\"\n",
    "\n",
    "    # Load model and test files\n",
    "    try:\n",
    "        # Load configuration\n",
    "        with open(config_path, 'r') as f:\n",
    "            cfg = yaml.safe_load(f)\n",
    "\n",
    "        # Load model using evaluation helper\n",
    "        from visualization.evaluation import load_model_from_checkpoint\n",
    "\n",
    "        model = load_model_from_checkpoint(ckpt_path, len(LABELS), cfg)\n",
    "        print(\"‚úÖ Model loaded successfully\")\n",
    "\n",
    "        # Get test files\n",
    "        if 'irmas_root' in globals() and irmas_root:\n",
    "            # Sample a few test files from the dataset\n",
    "            all_wav_files = list(pathlib.Path(irmas_root).rglob(\"*.wav\"))\n",
    "            np.random.seed(42)  # For reproducibility\n",
    "            np.random.shuffle(all_wav_files)\n",
    "            val_split = int(len(all_wav_files) * 0.9)\n",
    "            test_wav_files = all_wav_files[val_split:][:5]  # Limit to 5 files\n",
    "\n",
    "            print(f\"üìä Running inference on {len(test_wav_files)} test files\")\n",
    "\n",
    "            # Run inference on test files\n",
    "            for i, wav_file in enumerate(test_wav_files):\n",
    "                wav_path = str(wav_file)\n",
    "                print(f\"\\nüéµ Testing file {i + 1}/{len(test_wav_files)}: {pathlib.Path(wav_path).name}\")\n",
    "\n",
    "                # Run prediction with adaptive thresholds if available\n",
    "                from inference.predict import predict_with_ground_truth\n",
    "\n",
    "                result = predict_with_ground_truth(\n",
    "                    model, wav_path, cfg,\n",
    "                    show_ground_truth=True,\n",
    "                    thresholds=f1_thresholds\n",
    "                )\n",
    "\n",
    "                # Display ground truth if available\n",
    "                if \"ground_truth\" in result and result[\"ground_truth\"]:\n",
    "                    print(f\"üéØ Ground truth: {result['ground_truth']}\")\n",
    "\n",
    "                # Display sorted predictions\n",
    "                print(\"üìä Predicted instrument probabilities:\")\n",
    "                print(\"=\" * 40)\n",
    "\n",
    "                sorted_scores = sorted(result[\"predictions\"].items(), key=lambda x: x[1], reverse=True)\n",
    "                for label, score in sorted_scores:\n",
    "                    confidence = \"üî•\" if score > 0.5 else \"  \"\n",
    "                    print(f\"  {confidence} {label:<15} {score:.4f}\")\n",
    "\n",
    "                # Show prediction status\n",
    "                if \"correct\" in result:\n",
    "                    status = \"‚úÖ CORRECT\" if result[\"correct\"] else \"‚ùå INCORRECT\"\n",
    "                    print(f\"üéØ Prediction status: {status}\")\n",
    "\n",
    "                # Visualize first file only\n",
    "                if i == 0:\n",
    "                    try:\n",
    "                        from visualization.visualization import visualize_audio\n",
    "\n",
    "                        print(\"\\nüìà Visualizing waveform & spectrograms:\")\n",
    "                        visualize_audio(wav_path, cfg)\n",
    "                    except Exception as viz_error:\n",
    "                        print(f\"‚ö†Ô∏è Visualization error: {viz_error}\")\n",
    "\n",
    "            print(f\"\\nüéâ Inference complete on {len(test_wav_files)} test files!\")\n",
    "\n",
    "            # Run comprehensive evaluation if test directory exists\n",
    "            if pathlib.Path(test_data_dir).exists():\n",
    "                print(f\"\\nüîç Running comprehensive evaluation...\")\n",
    "                try:\n",
    "                    from visualization.evaluation import run_comprehensive_evaluation\n",
    "\n",
    "                    eval_results = run_comprehensive_evaluation(\n",
    "                        checkpoint_path=ckpt_path,\n",
    "                        test_dir=test_data_dir,\n",
    "                        config_path=config_path,\n",
    "                        threshold=0.5\n",
    "                    )\n",
    "\n",
    "                    if eval_results:\n",
    "                        print(\"‚úÖ Comprehensive evaluation completed!\")\n",
    "                except Exception as e:\n",
    "                    print(f\"‚ö†Ô∏è Evaluation error: {e}\")\n",
    "            else:\n",
    "                print(\"‚ö†Ô∏è Test data directory not found for comprehensive evaluation\")\n",
    "        else:\n",
    "            print(\"‚ùå Original IRMAS dataset root not found\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error during model loading or inference: {e}\")\n",
    "        import traceback\n",
    "\n",
    "        traceback.print_exc()"
   ],
   "id": "8f46a99e536eae05"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
