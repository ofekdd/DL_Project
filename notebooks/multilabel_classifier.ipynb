{
 "cells": [
  {
   "cell_type": "code",
   "id": "fae51c5c100772c5",
   "metadata": {},
   "source": [
    "# TODO: import stuff\n",
    "import sys\n",
    "import random\n",
    "import os\n",
    "import torch\n",
    "import librosa\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import yaml\n",
    "import urllib.request\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import warnings, tqdm\n",
    "from visualization.visualization import visualize_audio\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=tqdm.TqdmWarning)\n",
    "sys.modules['tqdm.notebook'] = tqdm\n",
    "sys.modules['tqdm.autonotebook'] = tqdm\n",
    "from tqdm import tqdm  # now `tqdm(...)` is always the console bar\n",
    "\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "\n",
    "if IN_COLAB:\n",
    "    # Clone the repository\n",
    "    !git clone https://github.com/ofekdd/DL_Project.git\n",
    "    %cd DL_Project\n",
    "\n",
    "    # Install dependencies\n",
    "    !pip install -r requirements.txt\n",
    "\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import yaml\n",
    "import os\n",
    "\n",
    "yaml_path = 'configs/multi_stft_cnn.yaml'\n",
    "\n",
    "# Open and load the YAML file\n",
    "with open(yaml_path, 'r') as file:\n",
    "    cfg = yaml.safe_load(file)\n",
    "\n",
    "print(\"9cnn configuration:\")\n",
    "for key, value in cfg.items():\n",
    "    print(f\"  {key}: {value}\")"
   ],
   "id": "4be9f8e58789698a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Download the IRMAS dataset if needed\n",
    "from data.download_irmas import main as download_irmas_main, find_irmas_root\n",
    "import pathlib\n",
    "\n",
    "# Determine the appropriate download location based on environment\n",
    "if IN_COLAB:\n",
    "    # For Colab, use Google Drive to store the dataset (already mounted)\n",
    "    DATA_CACHE = \"/content/drive/MyDrive/datasets/IRMAS\"\n",
    "else:\n",
    "    # For local environment, store in the project directory\n",
    "    DATA_CACHE = \"data/raw\"\n",
    "\n",
    "# Create the directory if it doesn't exist\n",
    "os.makedirs(DATA_CACHE, exist_ok=True)\n",
    "\n",
    "# Download and extract the dataset\n",
    "print(f\"Downloading IRMAS dataset to {DATA_CACHE}...\")\n",
    "download_irmas_main(pathlib.Path(DATA_CACHE))\n",
    "\n",
    "# Find the IRMAS dataset root\n",
    "irmas_root = find_irmas_root()\n",
    "if irmas_root:\n",
    "    print(f\"IRMAS dataset found at: {irmas_root}\")\n",
    "\n",
    "    # Define the processing output directory\n",
    "    PROCESSED_DIR = \"/content/IRMAS_features\" if IN_COLAB else \"data/processed\"\n",
    "\n",
    "    # Suggest the next step\n",
    "    print(f\"\\nTo preprocess the data, you can run:\")\n",
    "    print(f\"python data/preprocess.py --in_dir {irmas_root} --out_dir {PROCESSED_DIR}\")\n",
    "\n",
    "    # Optional: Add a cell to automatically run preprocessing if needed\n",
    "    preprocess_cmd = f\"!python data/preprocess.py --in_dir {irmas_root} --out_dir {PROCESSED_DIR}\"\n",
    "    print(f\"\\nOr execute this command in the next cell:\")\n",
    "    print(preprocess_cmd)\n",
    "else:\n",
    "    print(\"Could not locate IRMAS dataset after download. Check paths and try again.\")"
   ],
   "id": "e96b51ebbb46946c",
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Check if preprocessing is needed and run the preprocessing step\n",
    "import os\n",
    "\n",
    "# Create the directory if it doesn't exist\n",
    "os.makedirs(PROCESSED_DIR, exist_ok=True)\n",
    "\n",
    "# Check if preprocessing is needed\n",
    "if irmas_root and not os.path.exists(f\"{PROCESSED_DIR}/train\") or len(os.listdir(f\"{PROCESSED_DIR}/train\")) == 0:\n",
    "    print(f\"Starting preprocessing from {irmas_root} to {PROCESSED_DIR}...\")\n",
    "\n",
    "    # Run the preprocessing command\n",
    "    !python data/preprocess.py --in_dir {irmas_root} --out_dir {PROCESSED_DIR} --config configs/default.yaml\n",
    "\n",
    "    print(f\"Preprocessing complete. Features saved to {PROCESSED_DIR}\")\n",
    "else:\n",
    "    print(f\"Processed data already exists at {PROCESSED_DIR} - skipping preprocessing\")"
   ],
   "id": "3b8e4f045c26a78c",
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Import required modules for the model\n",
    "import torch\n",
    "from var import LABELS\n",
    "from models.multi_stft_cnn import MultiSTFTCNN\n",
    "\n",
    "n_classes = len(LABELS)\n",
    "\n",
    "# Create the model\n",
    "model = MultiSTFTCNN(\n",
    "    n_classes=n_classes,  # Number of instrument classes\n",
    "    n_branches=9,  # 3 FFT sizes Ã— 3 frequency bands\n",
    "    branch_output_dim=128  # Default value for feature dimension\n",
    ")\n",
    "\n",
    "print(\"9 CNN Baseline Architecture:\")\n",
    "print(model)\n",
    "\n",
    "# Optional: Print model summary if torchinfo is available\n",
    "try:\n",
    "    from torchinfo import summary\n",
    "    # Create dummy input for the model (9 spectrograms with random dimensions)\n",
    "    dummy_input = [torch.zeros(1, 1, 20, 30) for _ in range(9)]\n",
    "    print(\"\\nModel Summary:\")\n",
    "    summary(model, input_data=dummy_input)\n",
    "except ImportError:\n",
    "    print(\"\\nInstall torchinfo for detailed model summary: pip install torchinfo\")"
   ],
   "id": "17f023b62a55eedb",
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "try:\n",
    "    from training.train import main as train_main\n",
    "    train_main(cfg)\n",
    "    print(\"Training completed!\")\n",
    "except Exception as e:\n",
    "    print(f\"Error with direct import: {e}\")\n",
    "    print(\"Falling back to shell command\")\n",
    "    !python -m training.train --config {cfg}"
   ],
   "id": "761c3efe9b680c00",
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": "# TODO: Test and visualize",
   "id": "f97e4a403da5d6cc",
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
